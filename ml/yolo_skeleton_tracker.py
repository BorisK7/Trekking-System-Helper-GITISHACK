#!/usr/bin/env python3
"""
ğŸ¦´ YOLO Skeleton Tracker
========================
ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¸ Ğ½Ğ°Ğ´Ñ‘Ğ¶Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞºĞµÑ€ Ğ»ÑĞ´ĞµĞ¹ Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ¾Ğ¹ ÑĞºĞµĞ»ĞµÑ‚Ğ¾Ğ².
Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ YOLOv8-pose.

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python yolo_skeleton_tracker.py test.mp4
    python yolo_skeleton_tracker.py test.mp4 --model m  # medium Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    python yolo_skeleton_tracker.py test.mp4 --conf 0.5
"""

import cv2
import numpy as np
from pathlib import Path
from collections import deque
from dataclasses import dataclass, field
from typing import List, Tuple, Dict, Optional
import colorsys
import time


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¦´ Ğ¡ĞšĞ•Ğ›Ğ•Ğ¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ğ¡Ğ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ ÑĞºĞµĞ»ĞµÑ‚Ğ° COCO
SKELETON_CONNECTIONS = [
    # Ğ“Ğ¾Ğ»Ğ¾Ğ²Ğ°
    (0, 1), (0, 2), (1, 3), (2, 4),
    # Ğ¢Ğ¾Ñ€Ñ
    (5, 6), (5, 11), (6, 12), (11, 12),
    # Ğ›ĞµĞ²Ğ°Ñ Ñ€ÑƒĞºĞ°
    (5, 7), (7, 9),
    # ĞŸÑ€Ğ°Ğ²Ğ°Ñ Ñ€ÑƒĞºĞ°
    (6, 8), (8, 10),
    # Ğ›ĞµĞ²Ğ°Ñ Ğ½Ğ¾Ğ³Ğ°
    (11, 13), (13, 15),
    # ĞŸÑ€Ğ°Ğ²Ğ°Ñ Ğ½Ğ¾Ğ³Ğ°
    (12, 14), (14, 16)
]

# ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡ĞµĞº
KEYPOINT_NAMES = [
    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
    'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
    'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
]

# Ğ¦Ğ²ĞµÑ‚Ğ° Ğ´Ğ»Ñ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ñ‚ĞµĞ»Ğ°
LIMB_COLORS = {
    'head': (255, 200, 100),      # Ğ–Ñ‘Ğ»Ñ‚Ñ‹Ğ¹
    'torso': (100, 255, 100),     # Ğ—ĞµĞ»Ñ‘Ğ½Ñ‹Ğ¹
    'left_arm': (255, 100, 100),  # ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹
    'right_arm': (100, 100, 255), # Ğ¡Ğ¸Ğ½Ğ¸Ğ¹
    'left_leg': (255, 100, 255),  # Ğ Ğ¾Ğ·Ğ¾Ğ²Ñ‹Ğ¹
    'right_leg': (100, 255, 255), # Ğ“Ğ¾Ğ»ÑƒĞ±Ğ¾Ğ¹
}


def get_limb_color(connection: Tuple[int, int]) -> Tuple[int, int, int]:
    """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ†Ğ²ĞµÑ‚ Ğ´Ğ»Ñ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ"""
    i, j = connection
    
    if i <= 4 or j <= 4:
        return LIMB_COLORS['head']
    elif (i in [5, 6, 11, 12]) and (j in [5, 6, 11, 12]):
        return LIMB_COLORS['torso']
    elif i in [5, 7, 9] or j in [5, 7, 9]:
        return LIMB_COLORS['left_arm']
    elif i in [6, 8, 10] or j in [6, 8, 10]:
        return LIMB_COLORS['right_arm']
    elif i in [11, 13, 15] or j in [11, 13, 15]:
        return LIMB_COLORS['left_leg']
    else:
        return LIMB_COLORS['right_leg']


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ Ğ¢Ğ Ğ•ĞšĞ•Ğ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class TrackedPerson:
    """ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº"""
    id: int
    color: Tuple[int, int, int]
    
    # Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
    keypoints: Optional[np.ndarray] = None
    confidences: Optional[np.ndarray] = None
    bbox: Optional[Tuple[int, int, int, int]] = None
    
    # Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ
    trajectory: deque = field(default_factory=lambda: deque(maxlen=60))
    
    # Temporal
    frames_seen: int = 0
    frames_lost: int = 0
    confirmed: bool = False
    
    def get_center(self) -> Optional[Tuple[float, float]]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ†ĞµĞ½Ñ‚Ñ€ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° (Ğ¿Ğ¾ Ğ±Ñ‘Ğ´Ñ€Ğ°Ğ¼ Ğ¸Ğ»Ğ¸ bbox)"""
        if self.keypoints is not None:
            # Ğ¦ĞµĞ½Ñ‚Ñ€ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ñ‘Ğ´Ñ€Ğ°Ğ¼Ğ¸ (Ñ‚Ğ¾Ñ‡ĞºĞ¸ 11 Ğ¸ 12)
            left_hip = self.keypoints[11]
            right_hip = self.keypoints[12]
            
            if left_hip[0] > 0 and right_hip[0] > 0:
                return ((left_hip[0] + right_hip[0]) / 2,
                       (left_hip[1] + right_hip[1]) / 2)
            
            # Fallback: Ñ†ĞµĞ½Ñ‚Ñ€ Ğ¿Ğ»ĞµÑ‡
            left_shoulder = self.keypoints[5]
            right_shoulder = self.keypoints[6]
            
            if left_shoulder[0] > 0 and right_shoulder[0] > 0:
                return ((left_shoulder[0] + right_shoulder[0]) / 2,
                       (left_shoulder[1] + right_shoulder[1]) / 2)
        
        if self.bbox:
            x, y, w, h = self.bbox
            return (x + w / 2, y + h / 2)
        
        return None
    
    def update(self, keypoints: np.ndarray, confidences: np.ndarray,
               bbox: Tuple[int, int, int, int]):
        """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ"""
        self.keypoints = keypoints
        self.confidences = confidences
        self.bbox = bbox
        
        center = self.get_center()
        if center:
            self.trajectory.append(center)
        
        self.frames_seen += 1
        self.frames_lost = 0


class YOLOPoseTracker:
    """Ğ¢Ñ€ĞµĞºĞµÑ€ Ğ»ÑĞ´ĞµĞ¹ Ñ YOLO-pose"""
    
    def __init__(self, model_size: str = 'n', confidence: float = 0.3):
        """
        Args:
            model_size: 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x'
            confidence: ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ confidence
        """
        self.model_size = model_size
        self.confidence = confidence
        self.model = None
        
        self.persons: Dict[int, TrackedPerson] = {}
        self.next_id = 0
        self.colors = self._generate_colors(30)
        
        self.confirm_frames = 2
        self.lost_frames_max = 15
    
    def _generate_colors(self, n: int) -> List[Tuple[int, int, int]]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ€ĞºĞ¸Ğµ Ñ†Ğ²ĞµÑ‚Ğ°"""
        colors = []
        for i in range(n):
            hue = (i * 0.618033988749895) % 1.0
            rgb = colorsys.hsv_to_rgb(hue, 0.9, 1.0)
            colors.append(tuple(int(c * 255) for c in rgb[::-1]))
        return colors
    
    def _load_model(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ YOLO Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""
        if self.model is not None:
            return
        
        try:
            from ultralytics import YOLO
            model_name = f'yolov8{self.model_size}-pose.pt'
            self.model = YOLO(model_name)
            print(f"âœ“ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ {model_name}")
        except ImportError:
            print("âŒ ultralytics Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°!")
            print("   Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ: pip install ultralytics")
            raise
    
    def process_frame(self, frame: np.ndarray) -> List[TrackedPerson]:
        """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ĞºĞ°Ğ´Ñ€"""
        self._load_model()
        
        # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ
        results = self.model(frame, verbose=False, conf=self.confidence)
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ»ÑĞ´ĞµĞ¹
        detections = []
        for result in results:
            if result.keypoints is None:
                continue
            
            keypoints = result.keypoints.xy.cpu().numpy()
            confidences = result.keypoints.conf.cpu().numpy() if result.keypoints.conf is not None else None
            boxes = result.boxes.xyxy.cpu().numpy() if result.boxes is not None else None
            
            for i, kpts in enumerate(keypoints):
                conf = confidences[i] if confidences is not None else np.ones(17)
                
                if boxes is not None and i < len(boxes):
                    x1, y1, x2, y2 = map(int, boxes[i])
                    bbox = (x1, y1, x2 - x1, y2 - y1)
                else:
                    # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ bbox Ğ¿Ğ¾ Ñ‚Ğ¾Ñ‡ĞºĞ°Ğ¼
                    valid_pts = kpts[kpts[:, 0] > 0]
                    if len(valid_pts) > 0:
                        x1, y1 = valid_pts.min(axis=0)
                        x2, y2 = valid_pts.max(axis=0)
                        bbox = (int(x1), int(y1), int(x2 - x1), int(y2 - y1))
                    else:
                        continue
                
                detections.append({
                    'keypoints': kpts,
                    'confidences': conf,
                    'bbox': bbox
                })
        
        # Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³
        for person in self.persons.values():
            person.frames_lost += 1
        
        self._match_detections(detections)
        
        # ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ
        for person in self.persons.values():
            if not person.confirmed and person.frames_seen >= self.confirm_frames:
                person.confirmed = True
        
        # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ°
        self._cleanup()
        
        return [p for p in self.persons.values() if p.confirmed]
    
    def _match_detections(self, detections: List[Dict]):
        """Ğ¡Ğ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ñ Ğ»ÑĞ´ÑŒĞ¼Ğ¸"""
        if not detections:
            return
        
        used = set()
        
        for person in list(self.persons.values()):
            center = person.get_center()
            if center is None:
                continue
            
            min_dist = float('inf')
            best_idx = -1
            
            for i, det in enumerate(detections):
                if i in used:
                    continue
                
                # Ğ¦ĞµĞ½Ñ‚Ñ€ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸
                x, y, w, h = det['bbox']
                det_center = (x + w / 2, y + h / 2)
                
                dist = np.sqrt(
                    (center[0] - det_center[0])**2 +
                    (center[1] - det_center[1])**2
                )
                
                if dist < min_dist and dist < 150:
                    min_dist = dist
                    best_idx = i
            
            if best_idx >= 0:
                det = detections[best_idx]
                person.update(det['keypoints'], det['confidences'], det['bbox'])
                used.add(best_idx)
        
        # ĞĞ¾Ğ²Ñ‹Ğµ Ğ»ÑĞ´Ğ¸
        for i, det in enumerate(detections):
            if i not in used:
                self._create_person(det)
    
    def _create_person(self, detection: Dict):
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°"""
        person = TrackedPerson(
            id=self.next_id,
            color=self.colors[self.next_id % len(self.colors)]
        )
        person.update(
            detection['keypoints'],
            detection['confidences'],
            detection['bbox']
        )
        self.persons[self.next_id] = person
        self.next_id += 1
    
    def _cleanup(self):
        """Ğ£Ğ´Ğ°Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ½Ğ½Ñ‹Ñ… Ğ»ÑĞ´ĞµĞ¹"""
        to_remove = [
            pid for pid, p in self.persons.items()
            if p.frames_lost > self.lost_frames_max
        ]
        for pid in to_remove:
            del self.persons[pid]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¨ Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SkeletonVisualizer:
    """ĞšÑ€Ğ°ÑĞ¸Ğ²Ğ°Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ° ÑĞºĞµĞ»ĞµÑ‚Ğ¾Ğ²"""
    
    def __init__(self, style: str = 'neon'):
        """
        Args:
            style: 'neon', 'classic', 'minimal'
        """
        self.style = style
        self.font = cv2.FONT_HERSHEY_SIMPLEX
    
    def draw_skeleton(self, frame: np.ndarray, person: TrackedPerson,
                      min_conf: float = 0.3) -> np.ndarray:
        """Ğ Ğ¸ÑÑƒĞµÑ‚ ÑĞºĞµĞ»ĞµÑ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°"""
        if person.keypoints is None:
            return frame
        
        kpts = person.keypoints
        confs = person.confidences if person.confidences is not None else np.ones(17)
        color = person.color
        
        # Ğ Ğ¸ÑÑƒĞµĞ¼ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ
        for i, j in SKELETON_CONNECTIONS:
            if i >= len(kpts) or j >= len(kpts):
                continue
            
            pt1 = kpts[i]
            pt2 = kpts[j]
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ñ‡ĞµĞº
            if pt1[0] <= 0 or pt1[1] <= 0 or pt2[0] <= 0 or pt2[1] <= 0:
                continue
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ confidence
            if confs[i] < min_conf or confs[j] < min_conf:
                continue
            
            pt1 = tuple(map(int, pt1))
            pt2 = tuple(map(int, pt2))
            
            if self.style == 'neon':
                # Glow ÑÑ„Ñ„ĞµĞºÑ‚
                limb_color = get_limb_color((i, j))
                
                # Ğ’Ğ½ĞµÑˆĞ½ĞµĞµ ÑĞ²ĞµÑ‡ĞµĞ½Ğ¸Ğµ
                cv2.line(frame, pt1, pt2, tuple(c // 4 for c in limb_color), 8)
                cv2.line(frame, pt1, pt2, tuple(c // 2 for c in limb_color), 5)
                # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ
                cv2.line(frame, pt1, pt2, limb_color, 3)
                # Ğ¯Ñ€ĞºĞ¸Ğ¹ Ñ†ĞµĞ½Ñ‚Ñ€
                cv2.line(frame, pt1, pt2, (255, 255, 255), 1)
                
            elif self.style == 'classic':
                cv2.line(frame, pt1, pt2, color, 3)
                
            else:  # minimal
                cv2.line(frame, pt1, pt2, color, 2)
        
        # Ğ Ğ¸ÑÑƒĞµĞ¼ Ñ‚Ğ¾Ñ‡ĞºĞ¸
        for i, pt in enumerate(kpts):
            if pt[0] <= 0 or pt[1] <= 0:
                continue
            if confs[i] < min_conf:
                continue
            
            pt = tuple(map(int, pt))
            
            if self.style == 'neon':
                # Glow
                cv2.circle(frame, pt, 8, tuple(c // 3 for c in color), -1)
                cv2.circle(frame, pt, 5, color, -1)
                cv2.circle(frame, pt, 2, (255, 255, 255), -1)
            else:
                cv2.circle(frame, pt, 4, (255, 255, 255), -1)
                cv2.circle(frame, pt, 3, color, -1)
        
        return frame
    
    def draw_trajectory(self, frame: np.ndarray, person: TrackedPerson) -> np.ndarray:
        """Ğ Ğ¸ÑÑƒĞµÑ‚ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ"""
        if len(person.trajectory) < 2:
            return frame
        
        pts = list(person.trajectory)
        color = person.color
        
        for i in range(1, len(pts)):
            alpha = i / len(pts)
            pt_color = tuple(int(c * alpha) for c in color)
            thickness = max(1, int(3 * alpha))
            
            pt1 = tuple(map(int, pts[i - 1]))
            pt2 = tuple(map(int, pts[i]))
            
            if self.style == 'neon':
                # Glow
                cv2.line(frame, pt1, pt2, tuple(c // 3 for c in pt_color), thickness + 4)
            
            cv2.line(frame, pt1, pt2, pt_color, thickness)
        
        return frame
    
    def draw_bbox(self, frame: np.ndarray, person: TrackedPerson) -> np.ndarray:
        """Ğ Ğ¸ÑÑƒĞµÑ‚ bounding box"""
        if person.bbox is None:
            return frame
        
        x, y, w, h = person.bbox
        color = person.color
        
        # Ğ£Ğ³Ğ¾Ğ»ĞºĞ¸
        corner = min(20, w // 5, h // 5)
        corners = [
            [(x, y), (x + corner, y)],
            [(x, y), (x, y + corner)],
            [(x + w, y), (x + w - corner, y)],
            [(x + w, y), (x + w, y + corner)],
            [(x, y + h), (x + corner, y + h)],
            [(x, y + h), (x, y + h - corner)],
            [(x + w, y + h), (x + w - corner, y + h)],
            [(x + w, y + h), (x + w, y + h - corner)],
        ]
        
        for p1, p2 in corners:
            if self.style == 'neon':
                cv2.line(frame, p1, p2, tuple(c // 2 for c in color), 4)
            cv2.line(frame, p1, p2, color, 2)
        
        return frame
    
    def draw_label(self, frame: np.ndarray, person: TrackedPerson) -> np.ndarray:
        """Ğ Ğ¸ÑÑƒĞµÑ‚ Ğ¼ĞµÑ‚ĞºÑƒ"""
        if person.bbox is None:
            return frame
        
        x, y, w, h = person.bbox
        color = person.color
        
        label = f"Person #{person.id}"
        
        (text_w, text_h), _ = cv2.getTextSize(label, self.font, 0.6, 2)
        
        # Ğ¤Ğ¾Ğ½
        cv2.rectangle(frame, (x, y - text_h - 10), (x + text_w + 10, y), color, -1)
        
        # Ğ¢ĞµĞºÑÑ‚
        cv2.putText(frame, label, (x + 5, y - 5),
                   self.font, 0.6, (0, 0, 0), 2)
        cv2.putText(frame, label, (x + 5, y - 5),
                   self.font, 0.6, (255, 255, 255), 1)
        
        return frame
    
    def render(self, frame: np.ndarray, persons: List[TrackedPerson],
               show_skeleton: bool = True,
               show_trajectory: bool = True,
               show_bbox: bool = True,
               show_label: bool = True) -> np.ndarray:
        """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ½Ğ´ĞµÑ€"""
        output = frame.copy()
        
        # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ (Ğ¿Ğ¾Ğ´ ÑĞºĞµĞ»ĞµÑ‚Ğ°Ğ¼Ğ¸)
        if show_trajectory:
            for person in persons:
                output = self.draw_trajectory(output, person)
        
        # Ğ¡ĞºĞµĞ»ĞµÑ‚Ñ‹
        if show_skeleton:
            for person in persons:
                output = self.draw_skeleton(output, person)
        
        # Bbox
        if show_bbox:
            for person in persons:
                output = self.draw_bbox(output, person)
        
        # ĞœĞµÑ‚ĞºĞ¸
        if show_label:
            for person in persons:
                output = self.draw_label(output, person)
        
        return output


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š Ğ˜ĞĞ¤Ğ-ĞŸĞĞĞ•Ğ›Ğ¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class InfoPanel:
    """Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ"""
    
    def __init__(self):
        self.font = cv2.FONT_HERSHEY_SIMPLEX
    
    def draw(self, frame: np.ndarray, persons: List[TrackedPerson],
             frame_idx: int, total_frames: int, fps: float) -> np.ndarray:
        
        h, w = frame.shape[:2]
        
        # Ğ¤Ğ¾Ğ½
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (280, 110), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        y = 35
        cv2.putText(frame, "YOLO SKELETON TRACKER", (20, y),
                   self.font, 0.6, (100, 200, 255), 2)
        
        y += 25
        cv2.putText(frame, f"Frame: {frame_idx + 1}/{total_frames}", (20, y),
                   self.font, 0.45, (200, 200, 200), 1)
        
        y += 20
        cv2.putText(frame, f"FPS: {fps:.1f}", (20, y),
                   self.font, 0.45, (200, 200, 200), 1)
        
        y += 20
        cv2.putText(frame, f"People: {len(persons)}", (20, y),
                   self.font, 0.45, (100, 255, 100), 1)
        
        # Progress bar
        y += 15
        progress = (frame_idx + 1) / total_frames
        bar_w = 240
        cv2.rectangle(frame, (20, y), (20 + bar_w, y + 6), (50, 50, 60), -1)
        cv2.rectangle(frame, (20, y), (20 + int(bar_w * progress), y + 6),
                     (100, 200, 255), -1)
        
        return frame


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¬ ĞŸĞ ĞĞ¦Ğ•Ğ¡Ğ¡ĞĞ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SkeletonProcessor:
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€"""
    
    def __init__(self, model_size: str = 'n', confidence: float = 0.3,
                 style: str = 'neon'):
        self.tracker = YOLOPoseTracker(model_size, confidence)
        self.visualizer = SkeletonVisualizer(style)
        self.info_panel = InfoPanel()
    
    def process_video(self, input_path: str, output_path: str,
                      show_preview: bool = True,
                      max_frames: Optional[int] = None,
                      show_skeleton: bool = True,
                      show_trajectory: bool = True,
                      show_bbox: bool = True):
        
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise ValueError(f"Cannot open: {input_path}")
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if max_frames:
            total = min(total, max_frames)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        print(f"\n{'â•'*55}")
        print(f"  ğŸ¦´ YOLO SKELETON TRACKER")
        print(f"{'â•'*55}")
        print(f"  ğŸ“ Input:  {input_path}")
        print(f"  ğŸ“ Output: {output_path}")
        print(f"  ğŸ“ Size:   {width}x{height} @ {fps:.1f} FPS")
        print(f"  ğŸ§  Model:  YOLOv8{self.tracker.model_size}-pose")
        print(f"  ğŸ¨ Style:  {self.visualizer.style}")
        print(f"{'â•'*55}")
        print(f"\n  Press Q to quit, P to pause\n")
        
        frame_times = []
        frame_idx = 0
        
        while frame_idx < total:
            ret, frame = cap.read()
            if not ret:
                break
            
            start = time.time()
            
            # Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³
            persons = self.tracker.process_frame(frame)
            
            # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
            output_frame = self.visualizer.render(
                frame, persons,
                show_skeleton=show_skeleton,
                show_trajectory=show_trajectory,
                show_bbox=show_bbox
            )
            
            # Ğ˜Ğ½Ñ„Ğ¾-Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ
            current_fps = 1.0 / np.mean(frame_times[-30:]) if frame_times else fps
            output_frame = self.info_panel.draw(
                output_frame, persons, frame_idx, total, current_fps
            )
            
            frame_time = time.time() - start
            frame_times.append(frame_time)
            
            out.write(output_frame)
            
            if show_preview:
                preview = cv2.resize(output_frame, (0, 0), fx=0.6, fy=0.6)
                cv2.imshow('YOLO Skeleton Tracker', preview)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("\n  Interrupted")
                    break
                elif key == ord('p'):
                    cv2.waitKey(0)
            
            if frame_idx % 30 == 0:
                progress = (frame_idx + 1) / total * 100
                avg_fps = 1.0 / np.mean(frame_times[-30:]) if frame_times else 0
                print(f"\r  [{progress:5.1f}%] FPS: {avg_fps:.1f} | People: {len(persons)}", end="")
            
            frame_idx += 1
        
        print(f"\n\n{'â•'*55}")
        print(f"  âœ… COMPLETE")
        print(f"{'â•'*55}")
        if frame_times:
            print(f"  â±  Avg time: {np.mean(frame_times)*1000:.1f} ms")
            print(f"  ğŸš€ Avg FPS: {1.0/np.mean(frame_times):.1f}")
        print(f"  ğŸ’¾ Saved: {output_path}")
        print(f"{'â•'*55}\n")
        
        cap.release()
        out.release()
        cv2.destroyAllWindows()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ğŸ¦´ YOLO Skeleton Tracker',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Model sizes:
  n - nano (fastest, least accurate)
  s - small
  m - medium (recommended)
  l - large
  x - xlarge (slowest, most accurate)

Styles:
  neon    - Colorful with glow effects
  classic - Simple colored skeleton
  minimal - Thin lines

Examples:
  python yolo_skeleton_tracker.py test.mp4
  python yolo_skeleton_tracker.py test.mp4 --model m --style neon
  python yolo_skeleton_tracker.py test.mp4 --conf 0.5 --no-bbox
        """
    )
    
    parser.add_argument('input', help='Input video')
    parser.add_argument('-o', '--output', default=None)
    parser.add_argument('--model', '-m', default='n',
                       choices=['n', 's', 'm', 'l', 'x'],
                       help='YOLO model size')
    parser.add_argument('--conf', type=float, default=0.3,
                       help='Confidence threshold')
    parser.add_argument('--style', default='neon',
                       choices=['neon', 'classic', 'minimal'],
                       help='Visual style')
    
    # Visualization toggles
    parser.add_argument('--no-skeleton', action='store_true')
    parser.add_argument('--no-trajectory', action='store_true')
    parser.add_argument('--no-bbox', action='store_true')
    
    parser.add_argument('--no-preview', action='store_true')
    parser.add_argument('--max-frames', type=int, default=None)
    
    args = parser.parse_args()
    
    if args.output is None:
        p = Path(args.input)
        args.output = str(p.parent / f"{p.stem}_skeleton.mp4")
    
    processor = SkeletonProcessor(
        model_size=args.model,
        confidence=args.conf,
        style=args.style
    )
    
    processor.process_video(
        args.input,
        args.output,
        show_preview=not args.no_preview,
        max_frames=args.max_frames,
        show_skeleton=not args.no_skeleton,
        show_trajectory=not args.no_trajectory,
        show_bbox=not args.no_bbox
    )


if __name__ == '__main__':
    main()

