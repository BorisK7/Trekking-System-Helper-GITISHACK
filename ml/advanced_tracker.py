#!/usr/bin/env python3
"""
üé≠ Advanced Theater Scene Tracker - –ü–õ–ê–ù –ú–ê–ö–°–ò–ú–£–ú
===================================================
–ú–æ–¥—É–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤:

1. –ü–æ—Ä–æ–≥–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (—è—Ä–∫–æ—Å—Ç—å, –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å, –∫–æ–Ω—Ç—Ä–∞—Å—Ç)
2. –§–∏–ª—å—Ç—Ä—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ —Ñ–æ—Ä–º–µ (area, aspect ratio, solidity)
3. Temporal —Ñ–∏–ª—å—Ç—Ä—ã (confirmation, lost frames, velocity clamping)
4. Kalman filter (—Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π)
5. YOLO verification (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
6. Optical flow consistency (–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è)
7. Motion history (–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–≤–∏–∂–µ–Ω–∏—è)

–ó–∞–ø—É—Å–∫:
    python advanced_tracker.py test.mp4
    python advanced_tracker.py test.mp4 --yolo          # –° YOLO –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
    python advanced_tracker.py test.mp4 --debug         # Debug —Ä–µ–∂–∏–º
    python advanced_tracker.py test.mp4 --config strict # –°—Ç—Ä–æ–≥–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã
"""

import cv2
import numpy as np
from pathlib import Path
from collections import deque
from dataclasses import dataclass, field
from typing import List, Tuple, Dict, Optional, Any, Callable
from abc import ABC, abstractmethod
import colorsys
import time


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class FilterConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
    
    # === –ü–æ—Ä–æ–≥–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã ===
    brightness_min: int = 15           # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —è—Ä–∫–æ—Å—Ç—å (–æ—Ç—Å–µ–∫–∞–µ–º –≥–ª—É–±–æ–∫–∏–µ —Ç–µ–Ω–∏)
    brightness_max: int = 245          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —è—Ä–∫–æ—Å—Ç—å (–æ—Ç—Å–µ–∫–∞–µ–º –ø—Ä–æ–∂–µ–∫—Ç–æ—Ä—ã)
    saturation_min: int = 10           # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å
    contrast_threshold: float = 0.3    # –ü–æ—Ä–æ–≥ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    
    # === –§–∏–ª—å—Ç—Ä—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É ===
    min_area: int = 1500               # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –æ–±—ä–µ–∫—Ç–∞ (px¬≤)
    max_area: int = 200000             # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –æ–±—ä–µ–∫—Ç–∞ (px¬≤)
    max_area_ratio: float = 0.25       # –ú–∞–∫—Å–∏–º—É–º % –æ—Ç –∫–∞–¥—Ä–∞
    
    # === –§–∏–ª—å—Ç—Ä—ã –ø–æ —Ñ–æ—Ä–º–µ ===
    min_aspect_ratio: float = 0.2      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
    max_aspect_ratio: float = 5.0      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
    min_solidity: float = 0.3          # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è "—Å–æ–ª–∏–¥–Ω–æ—Å—Ç—å" (–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å)
    min_extent: float = 0.2            # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π extent (area / bbox_area)
    
    # === Temporal —Ñ–∏–ª—å—Ç—Ä—ã ===
    confirm_frames: int = 3            # –ö–∞–¥—Ä–æ–≤ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
    lost_frames_max: int = 15          # –ö–∞–¥—Ä–æ–≤ –¥–æ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ—Ç–µ—Ä—è–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
    max_velocity: float = 100.0        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å (px/frame)
    velocity_smoothing: float = 0.7    # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (0-1)
    position_smoothing: float = 0.8    # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ (0-1)
    
    # === Matching ===
    max_match_distance: float = 120.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    
    # === Kalman filter ===
    use_kalman: bool = True            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Kalman filter
    kalman_process_noise: float = 0.03 # –®—É–º –ø—Ä–æ—Ü–µ—Å—Å–∞
    kalman_measurement_noise: float = 0.1  # –®—É–º –∏–∑–º–µ—Ä–µ–Ω–∏—è
    
    # === YOLO verification ===
    use_yolo: bool = False             # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å YOLO –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
    yolo_confidence: float = 0.3       # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è confidence YOLO
    yolo_every_n_frames: int = 3       # –ó–∞–ø—É—Å–∫–∞—Ç—å YOLO –∫–∞–∂–¥—ã–µ N –∫–∞–¥—Ä–æ–≤
    
    # === Optical flow ===
    use_optical_flow: bool = True      # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å optical flow
    flow_consistency_threshold: float = 0.5  # –ü–æ—Ä–æ–≥ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    
    @classmethod
    def relaxed(cls) -> 'FilterConfig':
        """–ú—è–≥–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–±–æ–ª—å—à–µ –¥–µ—Ç–µ–∫—Ü–∏–π, –±–æ–ª—å—à–µ —à—É–º–∞)"""
        return cls(
            min_area=800,
            confirm_frames=2,
            lost_frames_max=25,
            max_velocity=150,
            max_match_distance=150
        )
    
    @classmethod
    def strict(cls) -> 'FilterConfig':
        """–°—Ç—Ä–æ–≥–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–º–µ–Ω—å—à–µ —à—É–º–∞, –º–æ–∂–µ—Ç –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ–±—ä–µ–∫—Ç—ã)"""
        return cls(
            min_area=2500,
            confirm_frames=5,
            lost_frames_max=10,
            max_velocity=80,
            max_match_distance=80,
            min_solidity=0.4,
            brightness_max=235
        )
    
    @classmethod
    def theater(cls) -> 'FilterConfig':
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Ç–µ–∞—Ç—Ä–∞"""
        return cls(
            brightness_max=240,
            saturation_min=5,
            min_area=2000,
            max_area_ratio=0.20,
            min_aspect_ratio=0.25,
            max_aspect_ratio=4.0,
            confirm_frames=4,
            lost_frames_max=20,
            max_velocity=90,
            use_optical_flow=True
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß –ë–ê–ó–û–í–´–ï –§–ò–õ–¨–¢–†–´
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class BaseFilter(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
    
    def __init__(self, config: FilterConfig):
        self.config = config
        self.enabled = True
    
    @abstractmethod
    def apply(self, data: Any) -> Any:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä –∫ –¥–∞–Ω–Ω—ã–º"""
        pass
    
    @property
    def name(self) -> str:
        return self.__class__.__name__


class BrightnessFilter(BaseFilter):
    """–§–∏–ª—å—Ç—Ä –ø–æ —è—Ä–∫–æ—Å—Ç–∏ - –æ—Ç—Å–µ–∫–∞–µ—Ç –ø—Ä–æ–∂–µ–∫—Ç–æ—Ä—ã –∏ –≥–ª—É–±–æ–∫–∏–µ —Ç–µ–Ω–∏"""
    
    def apply(self, frame: np.ndarray) -> np.ndarray:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å–∫—É –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π (–Ω–µ —Å–ª–∏—à–∫–æ–º —è—Ä–∫–∏—Ö/—Ç—ë–º–Ω—ã—Ö)
        """
        if not self.enabled:
            return np.ones(frame.shape[:2], dtype=np.uint8) * 255
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –∏–ª–∏ –±–µ—Ä—ë–º V –∏–∑ HSV
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame
        
        # –°–æ–∑–¥–∞—ë–º –º–∞—Å–∫—É
        mask = np.ones_like(gray) * 255
        mask[gray < self.config.brightness_min] = 0   # –°–ª–∏—à–∫–æ–º —Ç—ë–º–Ω—ã–µ
        mask[gray > self.config.brightness_max] = 0   # –°–ª–∏—à–∫–æ–º —è—Ä–∫–∏–µ
        
        return mask


class SaturationFilter(BaseFilter):
    """–§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–∂–µ–∫—Ç–æ—Ä—ã –æ–±—ã—á–Ω–æ –±–µ–ª—ã–µ (–Ω–∏–∑–∫–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å)"""
    
    def apply(self, frame: np.ndarray) -> np.ndarray:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å–∫—É –ø–∏–∫—Å–µ–ª–µ–π —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å—é
        """
        if not self.enabled:
            return np.ones(frame.shape[:2], dtype=np.uint8) * 255
        
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        saturation = hsv[:, :, 1]
        
        # –ü–∏–∫—Å–µ–ª–∏ —Å –Ω–∏–∑–∫–æ–π –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å—é –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–∂–µ–∫—Ç–æ—Ä–∞–º–∏
        # –ù–û —Ç–∞–∫–∂–µ –º–æ–≥—É—Ç –±—ã—Ç—å –±–µ–ª–æ–π –æ–¥–µ–∂–¥–æ–π, –ø–æ—ç—Ç–æ–º—É –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å —è—Ä–∫–æ—Å—Ç—å—é
        value = hsv[:, :, 2]
        
        mask = np.ones_like(saturation) * 255
        # –û—Ç—Å–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ò –Ω–∏–∑–∫–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å –ò –≤—ã—Å–æ–∫–∞—è —è—Ä–∫–æ—Å—Ç—å (–ø—Ä–æ–∂–µ–∫—Ç–æ—Ä)
        spotlight_mask = (saturation < self.config.saturation_min) & (value > 230)
        mask[spotlight_mask] = 0
        
        return mask


class SizeFilter(BaseFilter):
    """–§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É –∫–æ–Ω—Ç—É—Ä–∞"""
    
    def apply(self, contours: List[np.ndarray], frame_shape: Tuple[int, int]) -> List[np.ndarray]:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–æ–Ω—Ç—É—Ä—ã –ø–æ –ø–ª–æ—â–∞–¥–∏
        """
        if not self.enabled:
            return contours
        
        frame_area = frame_shape[0] * frame_shape[1]
        max_area = min(self.config.max_area, frame_area * self.config.max_area_ratio)
        
        filtered = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if self.config.min_area <= area <= max_area:
                filtered.append(contour)
        
        return filtered


class ShapeFilter(BaseFilter):
    """–§–∏–ª—å—Ç—Ä –ø–æ —Ñ–æ—Ä–º–µ –∫–æ–Ω—Ç—É—Ä–∞ (aspect ratio, solidity, extent)"""
    
    def apply(self, contours: List[np.ndarray]) -> List[np.ndarray]:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–æ–Ω—Ç—É—Ä—ã –ø–æ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º
        """
        if not self.enabled:
            return contours
        
        filtered = []
        for contour in contours:
            # Bounding box
            x, y, w, h = cv2.boundingRect(contour)
            if h == 0:
                continue
            
            aspect_ratio = w / h
            
            # Aspect ratio check
            if not (self.config.min_aspect_ratio <= aspect_ratio <= self.config.max_aspect_ratio):
                continue
            
            # Area
            area = cv2.contourArea(contour)
            if area == 0:
                continue
            
            # Extent (area / bbox_area)
            bbox_area = w * h
            extent = area / bbox_area
            if extent < self.config.min_extent:
                continue
            
            # Solidity (area / convex_hull_area)
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            if hull_area > 0:
                solidity = area / hull_area
                if solidity < self.config.min_solidity:
                    continue
            
            filtered.append(contour)
        
        return filtered


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìà KALMAN FILTER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ObjectKalmanFilter:
    """Kalman filter –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
    
    def __init__(self, initial_pos: Tuple[float, float], 
                 process_noise: float = 0.03,
                 measurement_noise: float = 0.1):
        
        # 4 —Å–æ—Å—Ç–æ—è–Ω–∏—è: x, y, vx, vy
        # 2 –∏–∑–º–µ—Ä–µ–Ω–∏—è: x, y
        self.kf = cv2.KalmanFilter(4, 2)
        
        # Transition matrix (–º–æ–¥–µ–ª—å –¥–≤–∏–∂–µ–Ω–∏—è)
        self.kf.transitionMatrix = np.array([
            [1, 0, 1, 0],
            [0, 1, 0, 1],
            [0, 0, 1, 0],
            [0, 0, 0, 1]
        ], dtype=np.float32)
        
        # Measurement matrix
        self.kf.measurementMatrix = np.array([
            [1, 0, 0, 0],
            [0, 1, 0, 0]
        ], dtype=np.float32)
        
        # Process noise
        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * process_noise
        
        # Measurement noise
        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * measurement_noise
        
        # Initial state
        self.kf.statePost = np.array([
            [initial_pos[0]],
            [initial_pos[1]],
            [0],
            [0]
        ], dtype=np.float32)
        
        self.kf.errorCovPost = np.eye(4, dtype=np.float32)
    
    def predict(self) -> Tuple[float, float]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é –ø–æ–∑–∏—Ü–∏—é"""
        prediction = self.kf.predict()
        return (float(prediction[0]), float(prediction[1]))
    
    def update(self, measurement: Tuple[float, float]) -> Tuple[float, float]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–æ–∑–∏—Ü–∏—é"""
        measured = np.array([[measurement[0]], [measurement[1]]], dtype=np.float32)
        corrected = self.kf.correct(measured)
        return (float(corrected[0]), float(corrected[1]))
    
    def get_velocity(self) -> Tuple[float, float]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –æ—Ü–µ–Ω–∫—É —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        return (float(self.kf.statePost[2]), float(self.kf.statePost[3]))


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéØ –û–¢–°–õ–ï–ñ–ò–í–ê–ï–ú–´–ô –û–ë–™–ï–ö–¢
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class TrackedObject:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    
    id: int
    color: Tuple[int, int, int]
    
    # –ü–æ–∑–∏—Ü–∏—è –∏ –≥–µ–æ–º–µ—Ç—Ä–∏—è
    centroid: Optional[Tuple[float, float]] = None
    bbox: Optional[Tuple[int, int, int, int]] = None
    mask: Optional[np.ndarray] = None
    
    # –ò—Å—Ç–æ—Ä–∏—è
    trajectory: deque = field(default_factory=lambda: deque(maxlen=100))
    velocity_history: deque = field(default_factory=lambda: deque(maxlen=20))
    area_history: deque = field(default_factory=lambda: deque(maxlen=20))
    
    # Temporal —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    frames_seen: int = 0          # –°–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –≤–∏–¥–µ–ª–∏ –æ–±—ä–µ–∫—Ç
    frames_lost: int = 0          # –°–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –Ω–µ –≤–∏–¥–∏–º
    confirmed: bool = False        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –ª–∏ –æ–±—ä–µ–∫—Ç
    
    # Kalman filter
    kalman: Optional[ObjectKalmanFilter] = None
    
    # YOLO verification
    yolo_confirmed: bool = False   # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω YOLO
    yolo_class: str = ""           # –ö–ª–∞—Å—Å –æ—Ç YOLO
    yolo_confidence: float = 0.0   # Confidence –æ—Ç YOLO
    
    # Smoothed values
    smoothed_centroid: Optional[Tuple[float, float]] = None
    smoothed_velocity: Tuple[float, float] = (0, 0)
    
    def init_kalman(self, process_noise: float = 0.03, measurement_noise: float = 0.1):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Kalman filter"""
        if self.centroid:
            self.kalman = ObjectKalmanFilter(
                self.centroid, process_noise, measurement_noise
            )
    
    def update(self, centroid: Tuple[float, float], 
               bbox: Tuple[int, int, int, int],
               mask: Optional[np.ndarray] = None,
               config: Optional[FilterConfig] = None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç –Ω–æ–≤—ã–º –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º"""
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å
        if self.centroid is not None:
            raw_velocity = (
                centroid[0] - self.centroid[0],
                centroid[1] - self.centroid[1]
            )
            
            # Velocity clamping
            if config and config.max_velocity > 0:
                speed = np.sqrt(raw_velocity[0]**2 + raw_velocity[1]**2)
                if speed > config.max_velocity:
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å
                    scale = config.max_velocity / speed
                    raw_velocity = (raw_velocity[0] * scale, raw_velocity[1] * scale)
            
            self.velocity_history.append(raw_velocity)
            
            # Smoothed velocity
            if config:
                alpha = config.velocity_smoothing
                self.smoothed_velocity = (
                    alpha * self.smoothed_velocity[0] + (1 - alpha) * raw_velocity[0],
                    alpha * self.smoothed_velocity[1] + (1 - alpha) * raw_velocity[1]
                )
        
        # Position smoothing
        if config and self.centroid is not None:
            alpha = config.position_smoothing
            smoothed = (
                alpha * self.centroid[0] + (1 - alpha) * centroid[0],
                alpha * self.centroid[1] + (1 - alpha) * centroid[1]
            )
        else:
            smoothed = centroid
        
        # Kalman update
        if self.kalman:
            self.kalman.predict()
            kalman_pos = self.kalman.update(centroid)
            self.smoothed_centroid = kalman_pos
        else:
            self.smoothed_centroid = smoothed
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.centroid = centroid
        self.bbox = bbox
        self.mask = mask
        self.trajectory.append(self.smoothed_centroid or centroid)
        self.area_history.append(bbox[2] * bbox[3] if bbox else 0)
        
        self.frames_seen += 1
        self.frames_lost = 0
    
    def predict_position(self) -> Optional[Tuple[float, float]]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é –ø–æ–∑–∏—Ü–∏—é"""
        if self.kalman:
            return self.kalman.predict()
        elif self.centroid and len(self.velocity_history) > 0:
            # –ü—Ä–æ—Å—Ç–æ–µ –ª–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            return (
                self.centroid[0] + self.smoothed_velocity[0],
                self.centroid[1] + self.smoothed_velocity[1]
            )
        return self.centroid
    
    def get_average_velocity(self) -> Tuple[float, float]:
        """–°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∫–∞–¥—Ä—ã"""
        if not self.velocity_history:
            return (0, 0)
        vels = list(self.velocity_history)
        return (
            sum(v[0] for v in vels) / len(vels),
            sum(v[1] for v in vels) / len(vels)
        )
    
    def get_speed(self) -> float:
        """–¢–µ–∫—É—â–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å"""
        return np.sqrt(self.smoothed_velocity[0]**2 + self.smoothed_velocity[1]**2)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåä OPTICAL FLOW
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class OpticalFlowAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ optical flow –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è"""
    
    def __init__(self):
        self.prev_gray = None
        self.flow = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Farneback optical flow
        self.flow_params = dict(
            pyr_scale=0.5,
            levels=3,
            winsize=15,
            iterations=3,
            poly_n=5,
            poly_sigma=1.2,
            flags=0
        )
    
    def compute(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç optical flow –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∫–∞–¥—Ä–æ–º"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        if self.prev_gray is None:
            self.prev_gray = gray
            return None
        
        self.flow = cv2.calcOpticalFlowFarneback(
            self.prev_gray, gray, None, **self.flow_params
        )
        
        self.prev_gray = gray
        return self.flow
    
    def get_flow_at_point(self, point: Tuple[int, int]) -> Optional[Tuple[float, float]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä flow –≤ —Ç–æ—á–∫–µ"""
        if self.flow is None:
            return None
        
        x, y = int(point[0]), int(point[1])
        h, w = self.flow.shape[:2]
        
        if 0 <= x < w and 0 <= y < h:
            return (float(self.flow[y, x, 0]), float(self.flow[y, x, 1]))
        return None
    
    def check_consistency(self, obj: TrackedObject, 
                          threshold: float = 0.5) -> float:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ —Å optical flow.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç score –æ—Ç 0 (–Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ) –¥–æ 1 (–ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ).
        """
        if self.flow is None or obj.centroid is None:
            return 1.0  # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö - —Å—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–º
        
        flow_vec = self.get_flow_at_point(obj.centroid)
        if flow_vec is None:
            return 1.0
        
        obj_vel = obj.smoothed_velocity
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
        flow_mag = np.sqrt(flow_vec[0]**2 + flow_vec[1]**2)
        obj_mag = np.sqrt(obj_vel[0]**2 + obj_vel[1]**2)
        
        if flow_mag < 1 and obj_mag < 1:
            return 1.0  # –û–±–∞ –ø–æ—á—Ç–∏ –Ω–µ–ø–æ–¥–≤–∏–∂–Ω—ã
        
        if flow_mag < 1 or obj_mag < 1:
            # –û–¥–∏–Ω –¥–≤–∏–∂–µ—Ç—Å—è, –¥—Ä—É–≥–æ–π –Ω–µ—Ç
            return 0.5
        
        # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        dot = flow_vec[0] * obj_vel[0] + flow_vec[1] * obj_vel[1]
        cos_sim = dot / (flow_mag * obj_mag)
        
        # –°—Ö–æ–¥—Å—Ç–≤–æ –ø–æ –º–∞–≥–Ω–∏—Ç—É–¥–µ
        mag_ratio = min(flow_mag, obj_mag) / max(flow_mag, obj_mag)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score
        score = 0.7 * (cos_sim + 1) / 2 + 0.3 * mag_ratio
        
        return score
    
    def visualize(self, frame: np.ndarray, step: int = 16) -> np.ndarray:
        """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç optical flow"""
        if self.flow is None:
            return frame
        
        h, w = frame.shape[:2]
        output = frame.copy()
        
        # –†–∏—Å—É–µ–º —Å—Ç—Ä–µ–ª–∫–∏
        for y in range(0, h, step):
            for x in range(0, w, step):
                fx, fy = self.flow[y, x]
                
                # –î–ª–∏–Ω–∞ –≤–µ–∫—Ç–æ—Ä–∞
                mag = np.sqrt(fx*fx + fy*fy)
                if mag < 1:
                    continue
                
                # –¶–≤–µ—Ç –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
                angle = np.arctan2(fy, fx)
                hue = int((angle + np.pi) / (2 * np.pi) * 180)
                color = cv2.cvtColor(
                    np.uint8([[[hue, 255, 255]]]), 
                    cv2.COLOR_HSV2BGR
                )[0, 0].tolist()
                
                end_x = int(x + fx * 2)
                end_y = int(y + fy * 2)
                
                cv2.arrowedLine(output, (x, y), (end_x, end_y), color, 1, tipLength=0.3)
        
        return output


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ü§ñ YOLO VERIFIER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class YOLOVerifier:
    """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é YOLO"""
    
    def __init__(self, model_name: str = 'yolov8n.pt', confidence: float = 0.3):
        self.model = None
        self.model_name = model_name
        self.confidence = confidence
        self.last_detections = []
        self.frame_count = 0
        
        # –ö–ª–∞—Å—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç (–ª—é–¥–∏, –∏ –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—ä–µ–∫—Ç—ã)
        self.target_classes = {0: 'person'}  # COCO class 0 = person
    
    def _load_model(self):
        """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        if self.model is not None:
            return True
        
        try:
            from ultralytics import YOLO
            self.model = YOLO(self.model_name)
            print(f"‚úì YOLO ({self.model_name}) loaded")
            return True
        except ImportError:
            print("‚ö† ultralytics not installed, YOLO verification disabled")
            return False
        except Exception as e:
            print(f"‚ö† Failed to load YOLO: {e}")
            return False
    
    def detect(self, frame: np.ndarray) -> List[Dict]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –Ω–∞ –∫–∞–¥—Ä–µ"""
        if not self._load_model():
            return []
        
        results = self.model(frame, verbose=False, conf=self.confidence)
        
        detections = []
        for result in results:
            if result.boxes is None:
                continue
            
            boxes = result.boxes.xyxy.cpu().numpy()
            classes = result.boxes.cls.cpu().numpy()
            confs = result.boxes.conf.cpu().numpy()
            
            for i, (box, cls, conf) in enumerate(zip(boxes, classes, confs)):
                cls_id = int(cls)
                if cls_id in self.target_classes:
                    x1, y1, x2, y2 = map(int, box)
                    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                    
                    detections.append({
                        'bbox': (x1, y1, x2 - x1, y2 - y1),
                        'centroid': (cx, cy),
                        'class': self.target_classes[cls_id],
                        'confidence': float(conf)
                    })
        
        self.last_detections = detections
        return detections
    
    def verify_object(self, obj: TrackedObject, max_distance: float = 50) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ YOLO –¥–µ—Ç–µ–∫—Ü–∏—è —Ä—è–¥–æ–º —Å –æ–±—ä–µ–∫—Ç–æ–º.
        """
        if not self.last_detections or obj.centroid is None:
            return False
        
        for det in self.last_detections:
            dist = np.sqrt(
                (obj.centroid[0] - det['centroid'][0])**2 +
                (obj.centroid[1] - det['centroid'][1])**2
            )
            if dist < max_distance:
                obj.yolo_confirmed = True
                obj.yolo_class = det['class']
                obj.yolo_confidence = det['confidence']
                return True
        
        return False


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üé¨ –ì–õ–ê–í–ù–´–ô –¢–†–ï–ö–ï–†
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AdvancedTracker:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–µ—Ä —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤.
    """
    
    def __init__(self, config: Optional[FilterConfig] = None):
        self.config = config or FilterConfig.theater()
        
        # –§–∏–ª—å—Ç—Ä—ã
        self.brightness_filter = BrightnessFilter(self.config)
        self.saturation_filter = SaturationFilter(self.config)
        self.size_filter = SizeFilter(self.config)
        self.shape_filter = ShapeFilter(self.config)
        
        # Background subtractor
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=400,
            varThreshold=40,
            detectShadows=True
        )
        
        # Optical flow
        self.flow_analyzer = OpticalFlowAnalyzer() if self.config.use_optical_flow else None
        
        # YOLO verifier
        self.yolo_verifier = YOLOVerifier() if self.config.use_yolo else None
        
        # –û–±—ä–µ–∫—Ç—ã
        self.objects: Dict[int, TrackedObject] = {}
        self.next_id = 0
        self.colors = self._generate_colors(50)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_detections': 0,
            'filtered_brightness': 0,
            'filtered_size': 0,
            'filtered_shape': 0,
            'filtered_temporal': 0,
            'confirmed_objects': 0
        }
        
        self.frame_count = 0
    
    def _generate_colors(self, n: int) -> List[Tuple[int, int, int]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —è—Ä–∫—É—é –ø–∞–ª–∏—Ç—Ä—É"""
        colors = []
        for i in range(n):
            hue = (i * 0.618033988749895) % 1.0
            rgb = colorsys.hsv_to_rgb(hue, 0.85, 0.95)
            colors.append(tuple(int(c * 255) for c in rgb[::-1]))
        return colors
    
    def process_frame(self, frame: np.ndarray) -> List[TrackedObject]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–¥—Ä —á–µ—Ä–µ–∑ –≤–µ—Å—å pipeline —Ñ–∏–ª—å—Ç—Ä–æ–≤.
        """
        self.frame_count += 1
        h, w = frame.shape[:2]
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 1: Preprocessing & Background Subtraction
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        brightness_mask = self.brightness_filter.apply(frame)
        saturation_mask = self.saturation_filter.apply(frame)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –º–∞—Å–∫–∏
        combined_mask = cv2.bitwise_and(brightness_mask, saturation_mask)
        
        # Background subtraction
        fg_mask = self.bg_subtractor.apply(frame)
        fg_mask[fg_mask == 127] = 0  # –£–¥–∞–ª—è–µ–º —Ç–µ–Ω–∏
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—ã–µ –º–∞—Å–∫–∏
        fg_mask = cv2.bitwise_and(fg_mask, combined_mask)
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel, iterations=2)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 2: Contour Detection & Spatial Filtering
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        self.stats['total_detections'] = len(contours)
        
        # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É
        contours = self.size_filter.apply(contours, (h, w))
        self.stats['filtered_size'] = self.stats['total_detections'] - len(contours)
        
        # –§–∏–ª—å—Ç—Ä –ø–æ —Ñ–æ—Ä–º–µ
        before_shape = len(contours)
        contours = self.shape_filter.apply(contours)
        self.stats['filtered_shape'] = before_shape - len(contours)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 3: Create Detections
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        detections = []
        for contour in contours:
            x, y, cw, ch = cv2.boundingRect(contour)
            area = cv2.contourArea(contour)
            
            M = cv2.moments(contour)
            if M["m00"] > 0:
                cx = M["m10"] / M["m00"]
                cy = M["m01"] / M["m00"]
            else:
                cx, cy = x + cw / 2, y + ch / 2
            
            obj_mask = np.zeros((h, w), dtype=np.uint8)
            cv2.drawContours(obj_mask, [contour], -1, 255, -1)
            
            detections.append({
                'centroid': (cx, cy),
                'bbox': (x, y, cw, ch),
                'mask': obj_mask,
                'area': area
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–ª–æ—â–∞–¥–∏
        detections.sort(key=lambda d: d['area'], reverse=True)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 4: Optical Flow
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        if self.flow_analyzer:
            self.flow_analyzer.compute(frame)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 5: YOLO Verification (–∫–∞–∂–¥—ã–µ N –∫–∞–¥—Ä–æ–≤)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        if self.yolo_verifier and self.frame_count % self.config.yolo_every_n_frames == 0:
            self.yolo_verifier.detect(frame)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 6: Temporal Matching & Tracking
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º lost_frames –¥–ª—è –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        for obj in self.objects.values():
            obj.frames_lost += 1
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
        self._match_detections(detections)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # STAGE 7: Temporal Filtering & Cleanup
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã
        for obj in self.objects.values():
            if not obj.confirmed and obj.frames_seen >= self.config.confirm_frames:
                obj.confirmed = True
                self.stats['confirmed_objects'] += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º optical flow consistency
        if self.flow_analyzer:
            for obj in self.objects.values():
                if obj.confirmed:
                    consistency = self.flow_analyzer.check_consistency(obj)
                    # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å
        
        # YOLO verification
        if self.yolo_verifier:
            for obj in self.objects.values():
                if obj.confirmed and not obj.yolo_confirmed:
                    self.yolo_verifier.verify_object(obj)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        self._cleanup_lost_objects()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        return [obj for obj in self.objects.values() if obj.confirmed]
    
    def _match_detections(self, detections: List[Dict]):
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏"""
        
        if not detections:
            return
        
        used_detections = set()
        
        # –°–Ω–∞—á–∞–ª–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
        for obj_id, obj in list(self.objects.items()):
            if obj.centroid is None:
                continue
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
            predicted = obj.predict_position()
            if predicted is None:
                predicted = obj.centroid
            
            min_dist = float('inf')
            best_idx = -1
            
            for i, det in enumerate(detections):
                if i in used_detections:
                    continue
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏
                dist_current = np.sqrt(
                    (obj.centroid[0] - det['centroid'][0])**2 +
                    (obj.centroid[1] - det['centroid'][1])**2
                )
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
                dist_predicted = np.sqrt(
                    (predicted[0] - det['centroid'][0])**2 +
                    (predicted[1] - det['centroid'][1])**2
                )
                
                dist = min(dist_current, dist_predicted)
                
                # Velocity check
                if self.config.max_velocity > 0:
                    velocity_dist = np.sqrt(
                        (obj.centroid[0] - det['centroid'][0])**2 +
                        (obj.centroid[1] - det['centroid'][1])**2
                    )
                    if velocity_dist > self.config.max_velocity * 1.5:
                        continue  # –°–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ
                
                if dist < min_dist and dist < self.config.max_match_distance:
                    min_dist = dist
                    best_idx = i
            
            if best_idx >= 0:
                det = detections[best_idx]
                obj.update(det['centroid'], det['bbox'], det['mask'], self.config)
                used_detections.add(best_idx)
        
        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        for i, det in enumerate(detections):
            if i not in used_detections:
                self._create_object(det)
    
    def _create_object(self, detection: Dict):
        """–°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç"""
        obj = TrackedObject(
            id=self.next_id,
            color=self.colors[self.next_id % len(self.colors)]
        )
        
        obj.update(detection['centroid'], detection['bbox'], detection['mask'], self.config)
        
        if self.config.use_kalman:
            obj.init_kalman(
                self.config.kalman_process_noise,
                self.config.kalman_measurement_noise
            )
        
        self.objects[self.next_id] = obj
        self.next_id += 1
    
    def _cleanup_lost_objects(self):
        """–£–¥–∞–ª—è–µ—Ç –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã"""
        to_remove = []
        
        for obj_id, obj in self.objects.items():
            if obj.frames_lost > self.config.lost_frames_max:
                to_remove.append(obj_id)
            elif not obj.confirmed and obj.frames_lost > 3:
                # –ù–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã —É–¥–∞–ª—è–µ–º –±—ã—Å—Ç—Ä–µ–µ
                to_remove.append(obj_id)
        
        self.stats['filtered_temporal'] = len(to_remove)
        
        for obj_id in to_remove:
            del self.objects[obj_id]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üé® –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AdvancedVisualizer:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å debug-—Ä–µ–∂–∏–º–æ–º"""
    
    def __init__(self, show_debug: bool = False, show_flow: bool = False):
        self.show_debug = show_debug
        self.show_flow = show_flow
        self.font = cv2.FONT_HERSHEY_SIMPLEX
    
    def render(self, frame: np.ndarray, objects: List[TrackedObject],
               tracker: AdvancedTracker, frame_idx: int, 
               total_frames: int, fps: float) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä"""
        
        output = frame.copy()
        h, w = output.shape[:2]
        
        # Optical flow visualization
        if self.show_flow and tracker.flow_analyzer:
            output = tracker.flow_analyzer.visualize(output)
        
        # –ú–∞—Å–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤
        for obj in objects:
            if obj.mask is not None and obj.confirmed:
                overlay = output.copy()
                overlay[obj.mask > 0] = obj.color
                cv2.addWeighted(overlay, 0.3, output, 0.7, 0, output)
                
                # –ö–æ–Ω—Ç—É—Ä
                contours, _ = cv2.findContours(obj.mask, cv2.RETR_EXTERNAL,
                                              cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(output, contours, -1, obj.color, 2)
        
        # –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
        for obj in objects:
            if len(obj.trajectory) > 1 and obj.confirmed:
                pts = list(obj.trajectory)
                for i in range(1, len(pts)):
                    alpha = i / len(pts)
                    color = tuple(int(c * alpha) for c in obj.color)
                    thickness = max(1, int(3 * alpha))
                    pt1 = tuple(map(int, pts[i-1]))
                    pt2 = tuple(map(int, pts[i]))
                    cv2.line(output, pt1, pt2, color, thickness)
        
        # Bounding boxes –∏ –º–µ—Ç–∫–∏
        for obj in objects:
            if obj.bbox and obj.confirmed:
                x, y, bw, bh = obj.bbox
                
                # –°—Ç–∏–ª—å–Ω—ã–π bbox
                corner = min(20, bw // 5, bh // 5)
                corners = [
                    [(x, y), (x + corner, y)],
                    [(x, y), (x, y + corner)],
                    [(x + bw, y), (x + bw - corner, y)],
                    [(x + bw, y), (x + bw, y + corner)],
                    [(x, y + bh), (x + corner, y + bh)],
                    [(x, y + bh), (x, y + bh - corner)],
                    [(x + bw, y + bh), (x + bw - corner, y + bh)],
                    [(x + bw, y + bh), (x + bw, y + bh - corner)],
                ]
                for p1, p2 in corners:
                    cv2.line(output, p1, p2, obj.color, 2)
                
                # –ú–µ—Ç–∫–∞
                label = f"#{obj.id}"
                if obj.yolo_confirmed:
                    label += f" [{obj.yolo_class}]"
                
                speed = obj.get_speed()
                if speed > 1:
                    label += f" v:{speed:.0f}"
                
                cv2.putText(output, label, (x, y - 8),
                           self.font, 0.5, (0, 0, 0), 3)
                cv2.putText(output, label, (x, y - 8),
                           self.font, 0.5, obj.color, 1)
        
        # –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã
        for obj in objects:
            if obj.smoothed_centroid and obj.confirmed:
                center = tuple(map(int, obj.smoothed_centroid))
                cv2.circle(output, center, 6, (255, 255, 255), 2)
                cv2.circle(output, center, 4, obj.color, -1)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –ø–∞–Ω–µ–ª—å
        self._draw_info_panel(output, objects, tracker, frame_idx, total_frames, fps)
        
        # Debug –ø–∞–Ω–µ–ª—å
        if self.show_debug:
            self._draw_debug_panel(output, tracker)
        
        return output
    
    def _draw_info_panel(self, frame: np.ndarray, objects: List[TrackedObject],
                         tracker: AdvancedTracker, frame_idx: int,
                         total_frames: int, fps: float):
        """–†–∏—Å—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å"""
        h, w = frame.shape[:2]
        
        # –§–æ–Ω –ø–∞–Ω–µ–ª–∏
        panel_h = 130
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (300, panel_h), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        y = 35
        cv2.putText(frame, "ADVANCED TRACKER", (20, y),
                   self.font, 0.7, (100, 200, 255), 2)
        
        y += 25
        cv2.putText(frame, f"Frame: {frame_idx + 1}/{total_frames}", (20, y),
                   self.font, 0.45, (200, 200, 200), 1)
        
        y += 20
        cv2.putText(frame, f"FPS: {fps:.1f}", (20, y),
                   self.font, 0.45, (200, 200, 200), 1)
        
        y += 20
        confirmed = len([o for o in objects if o.confirmed])
        unconfirmed = len(tracker.objects) - confirmed
        cv2.putText(frame, f"Objects: {confirmed} confirmed, {unconfirmed} pending", (20, y),
                   self.font, 0.4, (200, 200, 200), 1)
        
        y += 20
        progress = (frame_idx + 1) / total_frames
        bar_w = 260
        cv2.rectangle(frame, (20, y), (20 + bar_w, y + 8), (50, 50, 60), -1)
        cv2.rectangle(frame, (20, y), (20 + int(bar_w * progress), y + 8),
                     (100, 200, 255), -1)
    
    def _draw_debug_panel(self, frame: np.ndarray, tracker: AdvancedTracker):
        """–†–∏—Å—É–µ—Ç debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        h, w = frame.shape[:2]
        
        # –§–æ–Ω debug –ø–∞–Ω–µ–ª–∏ (—Å–ø—Ä–∞–≤–∞)
        panel_w = 220
        overlay = frame.copy()
        cv2.rectangle(overlay, (w - panel_w - 10, 10), (w - 10, 200), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        x = w - panel_w
        y = 30
        
        cv2.putText(frame, "DEBUG INFO", (x, y),
                   self.font, 0.5, (255, 200, 100), 1)
        
        stats = [
            f"Raw detections: {tracker.stats['total_detections']}",
            f"Filtered (size): {tracker.stats['filtered_size']}",
            f"Filtered (shape): {tracker.stats['filtered_shape']}",
            f"Filtered (temporal): {tracker.stats['filtered_temporal']}",
            f"Total confirmed: {tracker.stats['confirmed_objects']}",
        ]
        
        y += 25
        for stat in stats:
            cv2.putText(frame, stat, (x, y),
                       self.font, 0.35, (180, 180, 180), 1)
            y += 18
        
        # Config info
        y += 10
        cv2.putText(frame, "Config:", (x, y), self.font, 0.4, (255, 200, 100), 1)
        y += 18
        
        config_info = [
            f"Confirm frames: {tracker.config.confirm_frames}",
            f"Max velocity: {tracker.config.max_velocity}",
            f"YOLO: {'ON' if tracker.config.use_yolo else 'OFF'}",
            f"Kalman: {'ON' if tracker.config.use_kalman else 'OFF'}",
        ]
        
        for info in config_info:
            cv2.putText(frame, info, (x, y),
                       self.font, 0.3, (150, 150, 150), 1)
            y += 15


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üé¨ –ü–†–û–¶–ï–°–°–û–†
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AdvancedProcessor:
    """–ì–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤–∏–¥–µ–æ"""
    
    def __init__(self, config: Optional[FilterConfig] = None,
                 show_debug: bool = False, show_flow: bool = False):
        self.tracker = AdvancedTracker(config)
        self.visualizer = AdvancedVisualizer(show_debug, show_flow)
    
    def process_video(self, input_path: str, output_path: str,
                      show_preview: bool = True,
                      max_frames: Optional[int] = None):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ"""
        
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise ValueError(f"Cannot open: {input_path}")
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if max_frames:
            total = min(total, max_frames)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        config = self.tracker.config
        
        print(f"\n{'‚ïê'*65}")
        print(f"  üé≠ ADVANCED THEATER TRACKER - PLAN MAXIMUM")
        print(f"{'‚ïê'*65}")
        print(f"  üìÅ Input:  {input_path}")
        print(f"  üìÅ Output: {output_path}")
        print(f"  üìê Size:   {width}x{height} @ {fps:.1f} FPS")
        print(f"  üìä Frames: {total}")
        print(f"{'‚îÄ'*65}")
        print(f"  ‚öôÔ∏è  CONFIG:")
        print(f"     ‚Ä¢ Brightness filter: {config.brightness_min}-{config.brightness_max}")
        print(f"     ‚Ä¢ Size filter: {config.min_area}-{config.max_area} px¬≤")
        print(f"     ‚Ä¢ Temporal: confirm={config.confirm_frames}, lost={config.lost_frames_max}")
        print(f"     ‚Ä¢ Max velocity: {config.max_velocity} px/frame")
        print(f"     ‚Ä¢ Kalman filter: {'ON' if config.use_kalman else 'OFF'}")
        print(f"     ‚Ä¢ YOLO verify: {'ON' if config.use_yolo else 'OFF'}")
        print(f"     ‚Ä¢ Optical flow: {'ON' if config.use_optical_flow else 'OFF'}")
        print(f"{'‚ïê'*65}")
        print(f"\n  Press 'Q' to quit, 'P' to pause, 'D' for debug\n")
        
        frame_times = []
        frame_idx = 0
        show_debug = self.visualizer.show_debug
        
        while frame_idx < total:
            ret, frame = cap.read()
            if not ret:
                break
            
            start = time.time()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞
            objects = self.tracker.process_frame(frame)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            current_fps = 1.0 / np.mean(frame_times[-30:]) if frame_times else fps
            output_frame = self.visualizer.render(
                frame, objects, self.tracker, frame_idx, total, current_fps
            )
            
            frame_time = time.time() - start
            frame_times.append(frame_time)
            
            out.write(output_frame)
            
            if show_preview:
                preview = cv2.resize(output_frame, (0, 0), fx=0.6, fy=0.6)
                cv2.imshow('Advanced Tracker', preview)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("\n  Interrupted")
                    break
                elif key == ord('p'):
                    cv2.waitKey(0)
                elif key == ord('d'):
                    self.visualizer.show_debug = not self.visualizer.show_debug
            
            if frame_idx % 30 == 0:
                progress = (frame_idx + 1) / total * 100
                avg_fps = 1.0 / np.mean(frame_times[-30:]) if frame_times else 0
                confirmed = len([o for o in objects if o.confirmed])
                print(f"\r  [{progress:5.1f}%] FPS: {avg_fps:.1f} | Objects: {confirmed}", end="")
            
            frame_idx += 1
        
        print(f"\n\n{'‚ïê'*65}")
        print(f"  ‚úÖ PROCESSING COMPLETE")
        print(f"{'‚ïê'*65}")
        if frame_times:
            print(f"  ‚è±  Avg frame time: {np.mean(frame_times)*1000:.1f} ms")
            print(f"  üöÄ Avg FPS: {1.0/np.mean(frame_times):.1f}")
        print(f"  üìä Total objects tracked: {self.tracker.stats['confirmed_objects']}")
        print(f"  üíæ Saved: {output_path}")
        print(f"{'‚ïê'*65}\n")
        
        cap.release()
        out.release()
        cv2.destroyAllWindows()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üöÄ MAIN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='üé≠ Advanced Theater Tracker - PLAN MAXIMUM',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Configurations:
  default  - Balanced settings for most cases
  relaxed  - More detections, more noise
  strict   - Less noise, may miss some objects
  theater  - Optimized for theater scenes (recommended)

Examples:
  python advanced_tracker.py test.mp4
  python advanced_tracker.py test.mp4 --config strict
  python advanced_tracker.py test.mp4 --yolo --debug
  python advanced_tracker.py test.mp4 --confirm-frames 5 --max-velocity 60
        """
    )
    
    parser.add_argument('input', help='Input video')
    parser.add_argument('-o', '--output', default=None, help='Output path')
    parser.add_argument('--config', default='theater',
                       choices=['default', 'relaxed', 'strict', 'theater'],
                       help='Preset configuration')
    
    # Filter overrides
    parser.add_argument('--min-area', type=int, default=None)
    parser.add_argument('--max-area', type=int, default=None)
    parser.add_argument('--confirm-frames', type=int, default=None)
    parser.add_argument('--lost-frames', type=int, default=None)
    parser.add_argument('--max-velocity', type=float, default=None)
    parser.add_argument('--brightness-max', type=int, default=None)
    
    # Features
    parser.add_argument('--yolo', action='store_true', help='Enable YOLO verification')
    parser.add_argument('--no-kalman', action='store_true', help='Disable Kalman filter')
    parser.add_argument('--no-flow', action='store_true', help='Disable optical flow')
    
    # Visualization
    parser.add_argument('--debug', action='store_true', help='Show debug info')
    parser.add_argument('--show-flow', action='store_true', help='Visualize optical flow')
    parser.add_argument('--no-preview', action='store_true')
    parser.add_argument('--max-frames', type=int, default=None)
    
    args = parser.parse_args()
    
    # Load config preset
    config_map = {
        'default': FilterConfig(),
        'relaxed': FilterConfig.relaxed(),
        'strict': FilterConfig.strict(),
        'theater': FilterConfig.theater()
    }
    config = config_map[args.config]
    
    # Apply overrides
    if args.min_area is not None:
        config.min_area = args.min_area
    if args.max_area is not None:
        config.max_area = args.max_area
    if args.confirm_frames is not None:
        config.confirm_frames = args.confirm_frames
    if args.lost_frames is not None:
        config.lost_frames_max = args.lost_frames
    if args.max_velocity is not None:
        config.max_velocity = args.max_velocity
    if args.brightness_max is not None:
        config.brightness_max = args.brightness_max
    
    config.use_yolo = args.yolo
    config.use_kalman = not args.no_kalman
    config.use_optical_flow = not args.no_flow
    
    # Output path
    if args.output is None:
        p = Path(args.input)
        args.output = str(p.parent / f"{p.stem}_advanced.mp4")
    
    # Process
    processor = AdvancedProcessor(
        config=config,
        show_debug=args.debug,
        show_flow=args.show_flow
    )
    
    processor.process_video(
        args.input,
        args.output,
        show_preview=not args.no_preview,
        max_frames=args.max_frames
    )


if __name__ == '__main__':
    main()

