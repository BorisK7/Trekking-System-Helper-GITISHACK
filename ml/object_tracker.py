"""
üé¨ Advanced Object Tracker with Segmentation
============================================
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç SAM 2 –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
–∏ —Å–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è–º–∏ –¥–≤–∏–∂–µ–Ω–∏—è.

Author: AI Assistant
"""

import cv2
import numpy as np
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Tuple, Any
from collections import deque
import colorsys
import time
from tqdm import tqdm

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üé® –í–ò–ó–£–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class VisualizationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    # –¶–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞ (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
    num_colors: int = 20
    
    # –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
    trail_length: int = 50  # –î–ª–∏–Ω–∞ "—Ö–≤–æ—Å—Ç–∞" —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
    trail_thickness: int = 3
    trail_fade: bool = True  # –ó–∞—Ç—É—Ö–∞–Ω–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
    
    # –ú–∞—Å–∫–∏
    mask_alpha: float = 0.4  # –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –º–∞—Å–æ–∫
    mask_outline: bool = True
    outline_thickness: int = 2
    
    # Bounding boxes
    show_bbox: bool = True
    bbox_thickness: int = 2
    
    # –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã
    show_centroid: bool = True
    centroid_radius: int = 6
    
    # –¢–µ–∫—Å—Ç –∏ –º–µ—Ç–∫–∏
    show_labels: bool = True
    font_scale: float = 0.7
    font_thickness: int = 2
    
    # –ò–Ω—Ñ–æ-–ø–∞–Ω–µ–ª—å
    show_info_panel: bool = True
    panel_width: int = 300
    panel_alpha: float = 0.85
    
    # –≠—Ñ—Ñ–µ–∫—Ç—ã
    glow_effect: bool = True
    motion_blur_trails: bool = False


def generate_color_palette(n: int) -> List[Tuple[int, int, int]]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é —Ü–≤–µ—Ç–æ–≤—É—é –ø–∞–ª–∏—Ç—Ä—É"""
    colors = []
    for i in range(n):
        hue = i / n
        saturation = 0.8 + 0.2 * np.sin(i * 0.5)  # –í–∞—Ä–∏–∞—Ü–∏—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏
        value = 0.9 + 0.1 * np.cos(i * 0.3)  # –í–∞—Ä–∏–∞—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏
        rgb = colorsys.hsv_to_rgb(hue, saturation, value)
        colors.append(tuple(int(c * 255) for c in rgb))
    return colors


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üì¶ –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class TrackedObject:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç"""
    id: int
    color: Tuple[int, int, int]
    trajectory: deque = field(default_factory=lambda: deque(maxlen=100))
    masks: List[np.ndarray] = field(default_factory=list)
    bboxes: List[Tuple[int, int, int, int]] = field(default_factory=list)
    centroids: List[Tuple[int, int]] = field(default_factory=list)
    velocities: List[Tuple[float, float]] = field(default_factory=list)
    active: bool = True
    label: str = ""
    confidence: float = 1.0
    
    def add_detection(self, mask: np.ndarray, bbox: Tuple[int, int, int, int], 
                      centroid: Tuple[int, int]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–µ –¥–µ—Ç–µ–∫—Ü–∏—é"""
        self.masks.append(mask)
        self.bboxes.append(bbox)
        self.centroids.append(centroid)
        self.trajectory.append(centroid)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å
        if len(self.centroids) >= 2:
            prev = self.centroids[-2]
            curr = self.centroids[-1]
            velocity = (curr[0] - prev[0], curr[1] - prev[1])
            self.velocities.append(velocity)
    
    @property
    def current_bbox(self) -> Optional[Tuple[int, int, int, int]]:
        return self.bboxes[-1] if self.bboxes else None
    
    @property
    def current_centroid(self) -> Optional[Tuple[int, int]]:
        return self.centroids[-1] if self.centroids else None
    
    @property
    def current_mask(self) -> Optional[np.ndarray]:
        return self.masks[-1] if self.masks else None
    
    @property
    def average_velocity(self) -> Tuple[float, float]:
        if not self.velocities:
            return (0, 0)
        recent = self.velocities[-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∫–∞–¥—Ä–æ–≤
        return (
            sum(v[0] for v in recent) / len(recent),
            sum(v[1] for v in recent) / len(recent)
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üñåÔ∏è –†–ï–ù–î–ï–†–ò–ù–ì –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò  
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class VisualizationRenderer:
    """–ö—Ä–∞—Å–∏–≤—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    
    def __init__(self, config: VisualizationConfig):
        self.config = config
        self.colors = generate_color_palette(config.num_colors)
        
    def render_frame(self, frame: np.ndarray, objects: List[TrackedObject],
                     frame_idx: int, total_frames: int, fps: float) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç –ø–æ–ª–Ω—ã–π –∫–∞–¥—Ä —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        output = frame.copy()
        
        # 1. –†–µ–Ω–¥–µ—Ä–∏–º –º–∞—Å–∫–∏
        output = self._render_masks(output, objects)
        
        # 2. –†–µ–Ω–¥–µ—Ä–∏–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
        output = self._render_trajectories(output, objects)
        
        # 3. –†–µ–Ω–¥–µ—Ä–∏–º bounding boxes
        if self.config.show_bbox:
            output = self._render_bboxes(output, objects)
        
        # 4. –†–µ–Ω–¥–µ—Ä–∏–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã
        if self.config.show_centroid:
            output = self._render_centroids(output, objects)
        
        # 5. –†–µ–Ω–¥–µ—Ä–∏–º –º–µ—Ç–∫–∏
        if self.config.show_labels:
            output = self._render_labels(output, objects)
        
        # 6. –†–µ–Ω–¥–µ—Ä–∏–º –∏–Ω—Ñ–æ-–ø–∞–Ω–µ–ª—å
        if self.config.show_info_panel:
            output = self._render_info_panel(output, objects, frame_idx, 
                                             total_frames, fps)
        
        return output
    
    def _render_masks(self, frame: np.ndarray, 
                      objects: List[TrackedObject]) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–∞—Å–∫–∏"""
        overlay = frame.copy()
        
        for obj in objects:
            if not obj.active or obj.current_mask is None:
                continue
                
            mask = obj.current_mask
            color = obj.color
            
            # –ó–∞–ª–∏–≤–∫–∞ –º–∞—Å–∫–∏
            overlay[mask > 0] = color
            
            # –ö–æ–Ω—Ç—É—Ä –º–∞—Å–∫–∏
            if self.config.mask_outline:
                contours, _ = cv2.findContours(
                    mask.astype(np.uint8), 
                    cv2.RETR_EXTERNAL, 
                    cv2.CHAIN_APPROX_SIMPLE
                )
                cv2.drawContours(frame, contours, -1, color, 
                               self.config.outline_thickness)
        
        # –°–º–µ—à–∏–≤–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º
        result = cv2.addWeighted(overlay, self.config.mask_alpha, 
                                 frame, 1 - self.config.mask_alpha, 0)
        return result
    
    def _render_trajectories(self, frame: np.ndarray,
                             objects: List[TrackedObject]) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è —Å —ç—Ñ—Ñ–µ–∫—Ç–æ–º –∑–∞—Ç—É—Ö–∞–Ω–∏—è"""
        for obj in objects:
            if not obj.active or len(obj.trajectory) < 2:
                continue
            
            points = list(obj.trajectory)
            color = obj.color
            
            for i in range(1, len(points)):
                if self.config.trail_fade:
                    # –≠—Ñ—Ñ–µ–∫—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è
                    alpha = i / len(points)
                    faded_color = tuple(int(c * alpha) for c in color)
                    thickness = max(1, int(self.config.trail_thickness * alpha))
                else:
                    faded_color = color
                    thickness = self.config.trail_thickness
                
                pt1 = tuple(map(int, points[i - 1]))
                pt2 = tuple(map(int, points[i]))
                
                # Glow —ç—Ñ—Ñ–µ–∫—Ç
                if self.config.glow_effect:
                    # –í–Ω–µ—à–Ω–µ–µ —Å–≤–µ—á–µ–Ω–∏–µ
                    glow_color = tuple(int(c * 0.3) for c in faded_color)
                    cv2.line(frame, pt1, pt2, glow_color, thickness + 4)
                
                cv2.line(frame, pt1, pt2, faded_color, thickness)
        
        return frame
    
    def _render_bboxes(self, frame: np.ndarray,
                       objects: List[TrackedObject]) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç bounding boxes"""
        for obj in objects:
            if not obj.active or obj.current_bbox is None:
                continue
            
            x, y, w, h = obj.current_bbox
            color = obj.color
            
            # –°—Ç–∏–ª—å–Ω—ã–π bbox —Å –∑–∞–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏
            corner_length = min(30, w // 4, h // 4)
            thickness = self.config.bbox_thickness
            
            # –í–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª
            cv2.line(frame, (x, y), (x + corner_length, y), color, thickness)
            cv2.line(frame, (x, y), (x, y + corner_length), color, thickness)
            
            # –í–µ—Ä—Ö–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª
            cv2.line(frame, (x + w, y), (x + w - corner_length, y), color, thickness)
            cv2.line(frame, (x + w, y), (x + w, y + corner_length), color, thickness)
            
            # –ù–∏–∂–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª
            cv2.line(frame, (x, y + h), (x + corner_length, y + h), color, thickness)
            cv2.line(frame, (x, y + h), (x, y + h - corner_length), color, thickness)
            
            # –ù–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª
            cv2.line(frame, (x + w, y + h), (x + w - corner_length, y + h), color, thickness)
            cv2.line(frame, (x + w, y + h), (x + w, y + h - corner_length), color, thickness)
        
        return frame
    
    def _render_centroids(self, frame: np.ndarray,
                          objects: List[TrackedObject]) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –æ–±—ä–µ–∫—Ç–æ–≤"""
        for obj in objects:
            if not obj.active or obj.current_centroid is None:
                continue
            
            center = tuple(map(int, obj.current_centroid))
            color = obj.color
            radius = self.config.centroid_radius
            
            # –í–Ω–µ—à–Ω–µ–µ –∫–æ–ª—å—Ü–æ
            cv2.circle(frame, center, radius + 3, (255, 255, 255), 2)
            # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫—Ä—É–≥
            cv2.circle(frame, center, radius, color, -1)
            # –ë–µ–ª–∞—è —Ç–æ—á–∫–∞ –≤ —Ü–µ–Ω—Ç—Ä–µ
            cv2.circle(frame, center, 2, (255, 255, 255), -1)
        
        return frame
    
    def _render_labels(self, frame: np.ndarray,
                       objects: List[TrackedObject]) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏"""
        font = cv2.FONT_HERSHEY_SIMPLEX
        
        for obj in objects:
            if not obj.active or obj.current_bbox is None:
                continue
            
            x, y, w, h = obj.current_bbox
            color = obj.color
            
            # –¢–µ–∫—Å—Ç –º–µ—Ç–∫–∏
            label = obj.label if obj.label else f"Object {obj.id}"
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å
            vel = obj.average_velocity
            speed = np.sqrt(vel[0]**2 + vel[1]**2)
            if speed > 0:
                label += f" | v={speed:.1f}px/f"
            
            # –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
            (text_w, text_h), baseline = cv2.getTextSize(
                label, font, self.config.font_scale, self.config.font_thickness
            )
            
            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            padding = 5
            bg_rect = (x, y - text_h - 2 * padding, 
                      text_w + 2 * padding, text_h + 2 * padding)
            
            # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω
            overlay = frame.copy()
            cv2.rectangle(overlay, 
                         (bg_rect[0], bg_rect[1]),
                         (bg_rect[0] + bg_rect[2], bg_rect[1] + bg_rect[3]),
                         color, -1)
            cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
            
            # –¢–µ–∫—Å—Ç
            cv2.putText(frame, label, 
                       (x + padding, y - padding),
                       font, self.config.font_scale, (255, 255, 255),
                       self.config.font_thickness)
        
        return frame
    
    def _render_info_panel(self, frame: np.ndarray, objects: List[TrackedObject],
                           frame_idx: int, total_frames: int, 
                           fps: float) -> np.ndarray:
        """–†–µ–Ω–¥–µ—Ä–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å"""
        h, w = frame.shape[:2]
        panel_w = self.config.panel_width
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–Ω–µ–ª—å
        panel = np.zeros((h, panel_w, 3), dtype=np.uint8)
        
        # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Ñ–æ–Ω
        for i in range(panel_w):
            alpha = 1.0 - (i / panel_w) * 0.3
            panel[:, i] = (int(25 * alpha), int(25 * alpha), int(30 * alpha))
        
        font = cv2.FONT_HERSHEY_SIMPLEX
        y_offset = 40
        line_height = 35
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        cv2.putText(panel, "OBJECT TRACKER", (20, y_offset),
                   font, 0.8, (100, 200, 255), 2)
        y_offset += 15
        
        # –õ–∏–Ω–∏—è-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        cv2.line(panel, (20, y_offset), (panel_w - 20, y_offset), 
                (60, 60, 70), 2)
        y_offset += line_height
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        active_objects = sum(1 for o in objects if o.active)
        
        stats = [
            ("Frame", f"{frame_idx + 1}/{total_frames}"),
            ("FPS", f"{fps:.1f}"),
            ("Objects", f"{active_objects}"),
            ("Progress", f"{(frame_idx + 1) / total_frames * 100:.1f}%"),
        ]
        
        for label, value in stats:
            cv2.putText(panel, label, (20, y_offset),
                       font, 0.5, (150, 150, 160), 1)
            cv2.putText(panel, value, (120, y_offset),
                       font, 0.5, (220, 220, 230), 1)
            y_offset += 25
        
        y_offset += 20
        
        # –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤
        cv2.putText(panel, "TRACKED OBJECTS", (20, y_offset),
                   font, 0.6, (100, 200, 255), 1)
        y_offset += 10
        cv2.line(panel, (20, y_offset), (panel_w - 20, y_offset), 
                (60, 60, 70), 1)
        y_offset += 25
        
        for obj in objects[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø–∞–Ω–µ–ª–∏
            if not obj.active:
                continue
            
            # –¶–≤–µ—Ç–Ω–æ–π –º–∞—Ä–∫–µ—Ä
            cv2.circle(panel, (30, y_offset - 5), 8, obj.color, -1)
            cv2.circle(panel, (30, y_offset - 5), 8, (255, 255, 255), 1)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—ä–µ–∫—Ç–µ
            label = obj.label if obj.label else f"Object {obj.id}"
            cv2.putText(panel, label[:15], (50, y_offset),
                       font, 0.45, (200, 200, 210), 1)
            
            # –°–∫–æ—Ä–æ—Å—Ç—å
            vel = obj.average_velocity
            speed = np.sqrt(vel[0]**2 + vel[1]**2)
            cv2.putText(panel, f"v: {speed:.1f}", (50, y_offset + 18),
                       font, 0.35, (120, 120, 130), 1)
            
            y_offset += 50
        
        # Progress bar
        progress_y = h - 50
        progress_w = panel_w - 40
        progress = (frame_idx + 1) / total_frames
        
        cv2.rectangle(panel, (20, progress_y), (20 + progress_w, progress_y + 10),
                     (40, 40, 50), -1)
        cv2.rectangle(panel, (20, progress_y), 
                     (20 + int(progress_w * progress), progress_y + 10),
                     (100, 200, 255), -1)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Å–Ω–æ–≤–Ω—ã–º –∫–∞–¥—Ä–æ–º
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–∞–¥—Ä
        result = np.zeros((h, w + panel_w, 3), dtype=np.uint8)
        result[:, :w] = frame
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–Ω–µ–ª—å —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é
        panel_area = result[:, w:]
        cv2.addWeighted(panel, self.config.panel_alpha, 
                       panel_area, 1 - self.config.panel_alpha, 0, panel_area)
        
        return result


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéØ –¢–†–ï–ö–ò–ù–ì –° –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï–ú OPENCV (–ë–ê–ó–û–í–´–ô)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class OpenCVTracker:
    """
    –ë–∞–∑–æ–≤—ã–π —Ç—Ä–µ–∫–µ—Ä –Ω–∞ OpenCV –¥–ª—è —Å–ª—É—á–∞–µ–≤ –±–µ–∑ SAM.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏—é:
    - Background subtraction –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è
    - Optical flow –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞
    """
    
    def __init__(self, min_area: int = 500, max_objects: int = 20):
        self.min_area = min_area
        self.max_objects = max_objects
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=500, varThreshold=50, detectShadows=True
        )
        self.objects: Dict[int, TrackedObject] = {}
        self.next_id = 0
        self.colors = generate_color_palette(50)
        
    def process_frame(self, frame: np.ndarray) -> List[TrackedObject]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–¥—Ä –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã"""
        # Background subtraction
        fg_mask = self.bg_subtractor.apply(frame)
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
        
        # –£–¥–∞–ª—è–µ–º —Ç–µ–Ω–∏ (–æ–Ω–∏ –∏–º–µ—é—Ç –∑–Ω–∞—á–µ–Ω–∏–µ 127)
        fg_mask[fg_mask == 127] = 0
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
        contours, _ = cv2.findContours(
            fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–ª–æ—â–∞–¥–∏ –∏ —Å–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
        detections = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < self.min_area:
                continue
            
            x, y, w, h = cv2.boundingRect(contour)
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
            mask = np.zeros(frame.shape[:2], dtype=np.uint8)
            cv2.drawContours(mask, [contour], -1, 255, -1)
            
            # –¶–µ–Ω—Ç—Ä–æ–∏–¥
            M = cv2.moments(contour)
            if M["m00"] > 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
            else:
                cx, cy = x + w // 2, y + h // 2
            
            detections.append({
                'bbox': (x, y, w, h),
                'centroid': (cx, cy),
                'mask': mask,
                'area': area
            })
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
        self._match_detections(detections)
        
        return list(self.objects.values())
    
    def _match_detections(self, detections: List[Dict]):
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏"""
        if not detections:
            # –ü–æ–º–µ—á–∞–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ
            for obj in self.objects.values():
                obj.active = False
            return
        
        if not self.objects:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –≤—Å–µ—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
            for det in detections[:self.max_objects]:
                self._create_object(det)
            return
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
        active_objects = [o for o in self.objects.values() if o.active]
        used_detections = set()
        
        for obj in active_objects:
            if obj.current_centroid is None:
                continue
            
            min_dist = float('inf')
            best_det_idx = -1
            
            for i, det in enumerate(detections):
                if i in used_detections:
                    continue
                
                dist = np.sqrt(
                    (obj.current_centroid[0] - det['centroid'][0])**2 +
                    (obj.current_centroid[1] - det['centroid'][1])**2
                )
                
                if dist < min_dist and dist < 100:  # –ü–æ—Ä–æ–≥ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                    min_dist = dist
                    best_det_idx = i
            
            if best_det_idx >= 0:
                det = detections[best_det_idx]
                obj.add_detection(det['mask'], det['bbox'], det['centroid'])
                used_detections.add(best_det_idx)
            else:
                obj.active = False
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        for i, det in enumerate(detections):
            if i not in used_detections:
                if len(self.objects) < self.max_objects:
                    self._create_object(det)
    
    def _create_object(self, detection: Dict) -> TrackedObject:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç"""
        obj = TrackedObject(
            id=self.next_id,
            color=self.colors[self.next_id % len(self.colors)]
        )
        obj.add_detection(
            detection['mask'],
            detection['bbox'],
            detection['centroid']
        )
        self.objects[self.next_id] = obj
        self.next_id += 1
        return obj


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ü§ñ –¢–†–ï–ö–ò–ù–ì –° SAM 2 (–ü–†–û–î–í–ò–ù–£–¢–´–ô)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class SAM2Tracker:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–µ—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SAM 2.
    –¢—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏: pip install git+https://github.com/facebookresearch/segment-anything-2.git
    """
    
    def __init__(self, model_size: str = "large"):
        """
        Args:
            model_size: 'tiny', 'small', 'base_plus', 'large'
        """
        self.model_size = model_size
        self.predictor = None
        self.objects: Dict[int, TrackedObject] = {}
        self.next_id = 0
        self.colors = generate_color_palette(50)
        self.initialized = False
        
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å SAM 2"""
        try:
            from sam2.build_sam import build_sam2_video_predictor
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
            model_configs = {
                'tiny': 'sam2_hiera_t.yaml',
                'small': 'sam2_hiera_s.yaml',
                'base_plus': 'sam2_hiera_b+.yaml',
                'large': 'sam2_hiera_l.yaml'
            }
            
            checkpoint_urls = {
                'tiny': 'facebook/sam2-hiera-tiny',
                'small': 'facebook/sam2-hiera-small',
                'base_plus': 'facebook/sam2-hiera-base-plus',
                'large': 'facebook/sam2-hiera-large'
            }
            
            config = model_configs.get(self.model_size, model_configs['large'])
            checkpoint = checkpoint_urls.get(self.model_size, checkpoint_urls['large'])
            
            self.predictor = build_sam2_video_predictor(config, checkpoint)
            self.initialized = True
            print(f"‚úì SAM 2 ({self.model_size}) –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except ImportError:
            print("‚ö† SAM 2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
            print("  pip install git+https://github.com/facebookresearch/segment-anything-2.git")
            raise
    
    def init_video(self, video_path: str):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞"""
        if not self.initialized:
            self._load_model()
        
        # SAM 2 video predictor initialization
        self.inference_state = self.predictor.init_state(video_path=video_path)
        
    def add_point_prompt(self, frame_idx: int, points: List[Tuple[int, int]], 
                         labels: List[int], object_id: Optional[int] = None):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ—á–µ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        
        Args:
            frame_idx: –ò–Ω–¥–µ–∫—Å –∫–∞–¥—Ä–∞
            points: –°–ø–∏—Å–æ–∫ —Ç–æ—á–µ–∫ [(x, y), ...]
            labels: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫ [1 –¥–ª—è –æ–±—ä–µ–∫—Ç–∞, 0 –¥–ª—è —Ñ–æ–Ω–∞]
            object_id: ID –æ–±—ä–µ–∫—Ç–∞ (–µ—Å–ª–∏ None - —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
        """
        if object_id is None:
            object_id = self.next_id
            self.next_id += 1
        
        points_np = np.array(points, dtype=np.float32)
        labels_np = np.array(labels, dtype=np.int32)
        
        _, out_obj_ids, out_mask_logits = self.predictor.add_new_points_or_box(
            inference_state=self.inference_state,
            frame_idx=frame_idx,
            obj_id=object_id,
            points=points_np,
            labels=labels_np,
        )
        
        return object_id
    
    def add_box_prompt(self, frame_idx: int, box: Tuple[int, int, int, int],
                       object_id: Optional[int] = None):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç box –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        
        Args:
            frame_idx: –ò–Ω–¥–µ–∫—Å –∫–∞–¥—Ä–∞
            box: Bounding box (x1, y1, x2, y2)
            object_id: ID –æ–±—ä–µ–∫—Ç–∞ (–µ—Å–ª–∏ None - —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
        """
        if object_id is None:
            object_id = self.next_id
            self.next_id += 1
        
        box_np = np.array(box, dtype=np.float32)
        
        _, out_obj_ids, out_mask_logits = self.predictor.add_new_points_or_box(
            inference_state=self.inference_state,
            frame_idx=frame_idx,
            obj_id=object_id,
            box=box_np,
        )
        
        return object_id
    
    def propagate(self):
        """–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ –≤—Å–µ –∫–∞–¥—Ä—ã –≤–∏–¥–µ–æ"""
        video_segments = {}
        
        for out_frame_idx, out_obj_ids, out_mask_logits in \
                self.predictor.propagate_in_video(self.inference_state):
            
            video_segments[out_frame_idx] = {
                out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()
                for i, out_obj_id in enumerate(out_obj_ids)
            }
        
        return video_segments


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ü¶¥ YOLO POSE ESTIMATOR (–î–õ–Ø –°–ö–ï–õ–ï–¢–û–í)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class YOLOPoseEstimator:
    """–û—Ü–µ–Ω–∫–∞ –ø–æ–∑—ã —Å –ø–æ–º–æ—â—å—é YOLO-Pose"""
    
    SKELETON_CONNECTIONS = [
        (0, 1), (0, 2), (1, 3), (2, 4),  # –ì–æ–ª–æ–≤–∞
        (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # –†—É–∫–∏
        (5, 11), (6, 12), (11, 12),  # –¢–æ—Ä—Å
        (11, 13), (13, 15), (12, 14), (14, 16)  # –ù–æ–≥–∏
    ]
    
    KEYPOINT_NAMES = [
        'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
        'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
        'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
        'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
    ]
    
    def __init__(self, model_size: str = 'n'):
        """
        Args:
            model_size: 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (xlarge)
        """
        self.model_size = model_size
        self.model = None
        self.colors = generate_color_palette(20)
        
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å YOLO-Pose"""
        try:
            from ultralytics import YOLO
            self.model = YOLO(f'yolov8{self.model_size}-pose.pt')
            print(f"‚úì YOLOv8-Pose ({self.model_size}) –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except ImportError:
            print("‚ö† ultralytics –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
            print("  pip install ultralytics")
            raise
    
    def process_frame(self, frame: np.ndarray) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–¥—Ä –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–∑—ã"""
        if self.model is None:
            self._load_model()
        
        results = self.model(frame, verbose=False)
        poses = []
        
        for result in results:
            if result.keypoints is None:
                continue
            
            keypoints = result.keypoints.xy.cpu().numpy()
            confidences = result.keypoints.conf.cpu().numpy() if result.keypoints.conf is not None else None
            boxes = result.boxes.xyxy.cpu().numpy() if result.boxes is not None else None
            
            for i, kpts in enumerate(keypoints):
                pose = {
                    'keypoints': kpts,
                    'confidences': confidences[i] if confidences is not None else None,
                    'bbox': boxes[i] if boxes is not None else None
                }
                poses.append(pose)
        
        return poses
    
    def draw_skeleton(self, frame: np.ndarray, poses: List[Dict], 
                      color_idx: int = 0) -> np.ndarray:
        """–†–∏—Å—É–µ—Ç —Å–∫–µ–ª–µ—Ç—ã –Ω–∞ –∫–∞–¥—Ä–µ"""
        for pose_idx, pose in enumerate(poses):
            color = self.colors[(color_idx + pose_idx) % len(self.colors)]
            kpts = pose['keypoints']
            confs = pose.get('confidences')
            
            # –†–∏—Å—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            for i, j in self.SKELETON_CONNECTIONS:
                if i < len(kpts) and j < len(kpts):
                    pt1 = tuple(map(int, kpts[i]))
                    pt2 = tuple(map(int, kpts[j]))
                    
                    if pt1[0] > 0 and pt1[1] > 0 and pt2[0] > 0 and pt2[1] > 0:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º confidence
                        if confs is not None:
                            if confs[i] < 0.5 or confs[j] < 0.5:
                                continue
                        
                        cv2.line(frame, pt1, pt2, color, 2)
            
            # –†–∏—Å—É–µ–º —Ç–æ—á–∫–∏
            for i, pt in enumerate(kpts):
                pt = tuple(map(int, pt))
                if pt[0] > 0 and pt[1] > 0:
                    if confs is not None and confs[i] < 0.5:
                        continue
                    
                    cv2.circle(frame, pt, 4, (255, 255, 255), -1)
                    cv2.circle(frame, pt, 3, color, -1)
        
        return frame


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üé¨ –ì–õ–ê–í–ù–´–ô –ü–†–û–¶–ï–°–°–û–† –í–ò–î–ï–û
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class VideoProcessor:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
    
    def __init__(self, tracker_type: str = 'opencv', 
                 vis_config: Optional[VisualizationConfig] = None):
        """
        Args:
            tracker_type: 'opencv', 'sam2'
            vis_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        """
        self.tracker_type = tracker_type
        self.vis_config = vis_config or VisualizationConfig()
        self.renderer = VisualizationRenderer(self.vis_config)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞
        if tracker_type == 'opencv':
            self.tracker = OpenCVTracker()
        elif tracker_type == 'sam2':
            self.tracker = SAM2Tracker()
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ç—Ä–µ–∫–µ—Ä–∞: {tracker_type}")
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π pose estimator
        self.pose_estimator = None
        
    def enable_pose_estimation(self, model_size: str = 'n'):
        """–í–∫–ª—é—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ–∑—ã"""
        self.pose_estimator = YOLOPoseEstimator(model_size)
        
    def process_video(self, input_path: str, output_path: str,
                      show_preview: bool = True, 
                      max_frames: Optional[int] = None):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ
        
        Args:
            input_path: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ
            output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ
            show_preview: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–µ–≤—å—é –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            max_frames: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ (None = –≤—Å–µ)
        """
        cap = cv2.VideoCapture(input_path)
        
        if not cap.isOpened():
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {input_path}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if max_frames:
            total_frames = min(total_frames, max_frames)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        output_width = width + (self.vis_config.panel_width if self.vis_config.show_info_panel else 0)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, height))
        
        print(f"\n{'='*60}")
        print(f"üé¨ –û–ë–†–ê–ë–û–¢–ö–ê –í–ò–î–ï–û")
        print(f"{'='*60}")
        print(f"üìÅ –í—Ö–æ–¥:  {input_path}")
        print(f"üìÅ –í—ã—Ö–æ–¥: {output_path}")
        print(f"üìê –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {width}x{height}")
        print(f"üéû  FPS: {fps}")
        print(f"üìä –ö–∞–¥—Ä–æ–≤: {total_frames}")
        print(f"üîß –¢—Ä–µ–∫–µ—Ä: {self.tracker_type}")
        print(f"{'='*60}\n")
        
        frame_times = []
        
        with tqdm(total=total_frames, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞", unit="–∫–∞–¥—Ä") as pbar:
            frame_idx = 0
            
            while frame_idx < total_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                
                start_time = time.time()
                
                # –¢—Ä–µ–∫–∏–Ω–≥ –æ–±—ä–µ–∫—Ç–æ–≤
                objects = self.tracker.process_frame(frame)
                
                # –†–∏—Å—É–µ–º –ø–æ–∑—ã –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                if self.pose_estimator:
                    poses = self.pose_estimator.process_frame(frame)
                    frame = self.pose_estimator.draw_skeleton(frame, poses)
                
                # –í—ã—á–∏—Å–ª—è–µ–º FPS
                if frame_times:
                    current_fps = 1.0 / np.mean(frame_times[-30:])
                else:
                    current_fps = fps
                
                # –†–µ–Ω–¥–µ—Ä–∏–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
                output_frame = self.renderer.render_frame(
                    frame, objects, frame_idx, total_frames, current_fps
                )
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–¥—Ä
                out.write(output_frame)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é
                if show_preview:
                    preview = cv2.resize(output_frame, (0, 0), fx=0.5, fy=0.5)
                    cv2.imshow('Object Tracker Preview', preview)
                    
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("\n‚ö† –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                        break
                    elif key == ord('p'):
                        cv2.waitKey(0)  # –ü–∞—É–∑–∞
                
                # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
                frame_time = time.time() - start_time
                frame_times.append(frame_time)
                
                pbar.update(1)
                frame_idx += 1
        
        # –û—á–∏—Å—Ç–∫–∞
        cap.release()
        out.release()
        cv2.destroyAllWindows()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_time = np.mean(frame_times) if frame_times else 0
        avg_fps = 1.0 / avg_time if avg_time > 0 else 0
        
        print(f"\n{'='*60}")
        print(f"‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print(f"{'='*60}")
        print(f"‚è±  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∫–∞–¥—Ä: {avg_time*1000:.1f} –º—Å")
        print(f"üöÄ –°—Ä–µ–¥–Ω–∏–π FPS –æ–±—Ä–∞–±–æ—Ç–∫–∏: {avg_fps:.1f}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        print(f"{'='*60}\n")
        
        return output_path


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üöÄ –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='üé¨ Object Tracker with Beautiful Visualization')
    parser.add_argument('input', type=str, help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ')
    parser.add_argument('-o', '--output', type=str, default=None,
                       help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: input_tracked.mp4)')
    parser.add_argument('-t', '--tracker', type=str, default='opencv',
                       choices=['opencv', 'sam2'],
                       help='–¢–∏–ø —Ç—Ä–µ–∫–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: opencv)')
    parser.add_argument('--pose', action='store_true',
                       help='–í–∫–ª—é—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É –ø–æ–∑—ã (YOLO)')
    parser.add_argument('--pose-model', type=str, default='n',
                       choices=['n', 's', 'm', 'l', 'x'],
                       help='–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ YOLO-Pose')
    parser.add_argument('--no-preview', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–µ–≤—å—é')
    parser.add_argument('--max-frames', type=int, default=None,
                       help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤')
    parser.add_argument('--no-panel', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å')
    parser.add_argument('--trail-length', type=int, default=50,
                       help='–î–ª–∏–Ω–∞ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏')
    
    args = parser.parse_args()
    
    # –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
    if args.output is None:
        input_path = Path(args.input)
        args.output = str(input_path.parent / f"{input_path.stem}_tracked.mp4")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    vis_config = VisualizationConfig(
        show_info_panel=not args.no_panel,
        trail_length=args.trail_length
    )
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = VideoProcessor(
        tracker_type=args.tracker,
        vis_config=vis_config
    )
    
    # –í–∫–ª—é—á–∞–µ–º pose estimation –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if args.pose:
        processor.enable_pose_estimation(args.pose_model)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
    processor.process_video(
        input_path=args.input,
        output_path=args.output,
        show_preview=not args.no_preview,
        max_frames=args.max_frames
    )


if __name__ == '__main__':
    main()

